{
  "items": [
    {
      "text": "Ôªø\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\__init__.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "f01a374e9c81e3db89b3a42940c4d6a5447684986a1296e42bf13f196eed6295"
      }
    },
    {
      "text": "Ôªøimport sqlite3\r\nfrom pathlib import Path\r\n\r\n# Nom d'utilisateur\r\nUSER_NAME = \"Dylan\"\r\n\r\n# Chemin de la base SQLite\r\nDB_PATH = Path(__file__).resolve().parent / \"prefs.db\"\r\n\r\n\r\ndef db():\r\n    \"\"\"Retourne une connexion SQLite avec Row factory activ√©e.\"\"\"\r\n    conn = sqlite3.connect(DB_PATH)\r\n    conn.row_factory = sqlite3.Row\r\n    return conn\r\n\r\n\r\ndef init_db():\r\n    \"\"\"Cr√©e les tables n√©cessaires si elles n‚Äôexistent pas.\"\"\"\r\n    conn = db()\r\n    cur = conn.cursor()\r\n\r\n    # Table feedback (like/dislike)\r\n    cur.execute(\"\"\"\r\n    CREATE TABLE IF NOT EXISTS feedback (\r\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\r\n        created_at TEXT NOT NULL,\r\n        user TEXT NOT NULL,\r\n        url TEXT NOT NULL,\r\n        domain TEXT,\r\n        title TEXT,\r\n        label TEXT CHECK(label IN ('like','dislike')) NOT NULL\r\n    );\r\n    \"\"\")\r\n\r\n    # Table des pr√©f√©rences utilisateur\r\n    cur.execute(\"\"\"\r\n    CREATE TABLE IF NOT EXISTS prefs (\r\n        id INTEGER PRIMARY KEY CHECK (id=1),\r\n        user",
      "meta": {
        "kind": "code",
        "file": "app\\database.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "508cbdbfa276409dada8bd18e42a7de36de9ae12dc22c482cc6dbe72afb04037"
      }
    },
    {
      "text": "e des pr√©f√©rences utilisateur\r\n    cur.execute(\"\"\"\r\n    CREATE TABLE IF NOT EXISTS prefs (\r\n        id INTEGER PRIMARY KEY CHECK (id=1),\r\n        user TEXT NOT NULL,\r\n        preferred_domains TEXT DEFAULT '',\r\n        blocked_domains TEXT DEFAULT '',\r\n        preferred_keywords TEXT DEFAULT '',\r\n        blocked_keywords TEXT DEFAULT '',\r\n        like_weight REAL DEFAULT 1.0,\r\n        dislike_weight REAL DEFAULT -1.0,\r\n        domain_boost REAL DEFAULT 0.6,\r\n        keyword_boost REAL DEFAULT 0.4,\r\n        strict_block INTEGER DEFAULT 0\r\n    );\r\n    \"\"\")\r\n\r\n    # Table d‚Äôhistorique des recherches (pour la nouveaut√©)\r\n    cur.execute(\"\"\"\r\n    CREATE TABLE IF NOT EXISTS history (\r\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\r\n        created_at TEXT NOT NULL,\r\n        user TEXT NOT NULL,\r\n        query TEXT NOT NULL,\r\n        url TEXT NOT NULL,\r\n        domain TEXT\r\n    );\r\n    \"\"\")\r\n\r\n    # S‚Äôassurer qu‚Äôune ligne prefs existe toujours pour l‚Äôutilisateur principal\r\n    cur.execute(\"INSE",
      "meta": {
        "kind": "code",
        "file": "app\\database.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "1c2945e3bf4f3e4f655f9ec2e672777decddda6b9f4e356630e52368dd42956b"
      }
    },
    {
      "text": "NULL,\r\n        domain TEXT\r\n    );\r\n    \"\"\")\r\n\r\n    # S‚Äôassurer qu‚Äôune ligne prefs existe toujours pour l‚Äôutilisateur principal\r\n    cur.execute(\"INSERT OR IGNORE INTO prefs (id, user) VALUES (1, ?)\", (USER_NAME,))\r\n\r\n    conn.commit()\r\n    conn.close()\r\n\r\n\r\ndef reset_db(confirm: bool = False):\r\n    \"\"\"R√©initialise la base (efface tout).\"\"\"\r\n    if not confirm:\r\n        print(\"‚ö†Ô∏è  Utilise reset_db(confirm=True) pour confirmer la suppression.\")\r\n        return\r\n    conn = db()\r\n    cur = conn.cursor()\r\n    cur.execute(\"DROP TABLE IF EXISTS feedback;\")\r\n    cur.execute(\"DROP TABLE IF EXISTS prefs;\")\r\n    cur.execute(\"DROP TABLE IF EXISTS history;\")\r\n    conn.commit()\r\n    conn.close()\r\n    print(\"üóëÔ∏è Base supprim√©e, relance init_db() pour la recr√©er.\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    print(\"üîß Initialisation de la base de donn√©es...\")\r\n    init_db()\r\n    print(f\"‚úÖ Base SQLite pr√™te : {DB_PATH}\")\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\database.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "d005e728e5d77d50a42b2773cb9def2403f01c40723d9f5bf085d99d274686ed"
      }
    },
    {
      "text": "   init_db()\r\n    print(f\"‚úÖ Base SQLite pr√™te : {DB_PATH}\")\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\database.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "19a5c59f95c8168b2842b44510723f884ec7bc4a90f4129e8cdfc63c850286f0"
      }
    },
    {
      "text": "Ôªøfrom pydantic import BaseModel\r\nfrom typing import Optional, List, Dict, Any\r\n\r\nclass SearchResult(BaseModel):\r\n    title: Optional[str]\r\n    url: str\r\n    snippet: Optional[str]\r\n    extract: Optional[str] = None\r\n    allowed_by_robots: Optional[bool] = None\r\n    domain: Optional[str] = None\r\n    score: Optional[float] = None  # <-- important\r\n\r\nclass DeepSearchOut(BaseModel):\r\n    query: str\r\n    results: List[SearchResult]\r\n    meta: Dict[str, Any]\r\n\r\nclass FeedbackIn(BaseModel):\r\n    url: str\r\n    domain: Optional[str] = None\r\n    title: Optional[str] = None\r\n    label: str  # 'like' | 'dislike'\r\n\r\nclass PrefsIn(BaseModel):\r\n    preferred_domains: Optional[str] = \"\"\r\n    blocked_domains: Optional[str] = \"\"\r\n    preferred_keywords: Optional[str] = \"\"\r\n    blocked_keywords: Optional[str] = \"\"\r\n    like_weight: Optional[float] = 1.0\r\n    dislike_weight: Optional[float] = -1.0\r\n    domain_boost: Optional[float] = 0.6\r\n    keyword_boost: Optional[float] = 0.4\r\n    strict_block: Optiona",
      "meta": {
        "kind": "code",
        "file": "app\\models.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "10f73a5e1377da6ca6f74f906d465a9f9b07d51af99c9c34e06b597f56ce1d8d"
      }
    },
    {
      "text": "  dislike_weight: Optional[float] = -1.0\r\n    domain_boost: Optional[float] = 0.6\r\n    keyword_boost: Optional[float] = 0.4\r\n    strict_block: Optional[bool] = False\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\models.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "5a785933ecf650cc74c270d3166c0a8a7323faf2765c8c7409ed5a7966f9db3e"
      }
    },
    {
      "text": "# app/models/code_change.py\r\nfrom pydantic import BaseModel, Field\r\nfrom typing import List\r\n\r\nclass CodeChange(BaseModel):\r\n    line_number: int = Field(..., ge=1, description=\"Num√©ro de ligne (1-based)\")\r\n    before: str = Field(..., description=\"Texte avant le changement\")\r\n    after: str = Field(..., description=\"Texte apr√®s (peut √™tre vide pour suppression)\")\r\n\r\nclass CodeReport(BaseModel):\r\n    file_path: str = Field(..., description=\"Chemin relatif du fichier √† modifier (dans le projet)\")\r\n    changes: List[CodeChange] = Field(..., description=\"Liste ordonn√©e des changements\")\r\n    objective: str = Field(\"\", description=\"Contexte/objectif du changement (optionnel)\")\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\models\\code_change.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "ba34a82cfd0a679f87cfbcd8c9400a418f34d948aa21fc191ff87a2b1cb62a32"
      }
    },
    {
      "text": "Ôªø\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\__init__.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "f01a374e9c81e3db89b3a42940c4d6a5447684986a1296e42bf13f196eed6295"
      }
    },
    {
      "text": "from fastapi import APIRouter\r\nfrom fastapi.responses import HTMLResponse\r\nfrom app.services.chat_engine import chat_with_user\r\n\r\nrouter = APIRouter()\r\n\r\n@router.post(\"/chat\")\r\ndef chat_api(message: str):\r\n    reply = chat_with_user(message)\r\n    return {\"reply\": reply}\r\n\r\n@router.get(\"/chat_ui\", response_class=HTMLResponse)\r\ndef chat_ui():\r\n    return \"\"\"\r\n<!doctype html><html lang=\"fr\"><head>\r\n<meta charset=\"utf-8\"><script src=\"https://cdn.tailwindcss.com\"></script>\r\n<title>Assistant IA ‚Äî Chat</title></head>\r\n<body class=\"bg-gray-50 p-6\">\r\n<h1 class=\"text-3xl font-bold mb-4\">üí¨ Assistant IA ‚Äî Chat (GPU)</h1>\r\n<div id=\"log\" class=\"bg-white rounded p-4 shadow mb-3 max-w-3xl h-[50vh] overflow-auto\"></div>\r\n<div class=\"flex gap-2\">\r\n  <input id=\"msg\" class=\"border rounded px-3 py-2 w-2/3\" placeholder=\"Parle avec ton assistant\">\r\n  <button onclick=\"send()\" class=\"bg-indigo-600 text-white px-4 py-2 rounded\">Envoyer</button>\r\n</div>\r\n<script>\r\nconst log = document.getElementById('log');\r\nfun",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\chat.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "b59031339b9ce4ddbdf5870d37eb83693fa86cad6a04af3935ba90ca90de7a73"
      }
    },
    {
      "text": "click=\"send()\" class=\"bg-indigo-600 text-white px-4 py-2 rounded\">Envoyer</button>\r\n</div>\r\n<script>\r\nconst log = document.getElementById('log');\r\nfunction add(role, text){\r\n  const b = document.createElement('div');\r\n  b.className = \"mb-2\";\r\n  b.innerHTML = `<b>${role}:</b> ${text}`;\r\n  log.appendChild(b); log.scrollTop = log.scrollHeight;\r\n}\r\nasync function send(){\r\n  const i = document.getElementById('msg'); const m = i.value.trim(); if(!m) return;\r\n  add(\"Toi\", m); i.value = \"\";\r\n  const res = await fetch(`/chat?message=${encodeURIComponent(m)}`, {method:\"POST\"});\r\n  const data = await res.json();\r\n  add(\"Assistant\", data.reply);\r\n}\r\n</script>\r\n</body></html>\r\n    \"\"\"\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\chat.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "a10328c1310d6f44eb68e964fcf806ae795d5bbe7b45dfd59119662d02b32924"
      }
    },
    {
      "text": "# app/routers/code_review.py\r\nfrom fastapi import APIRouter, Query, HTTPException\r\nfrom fastapi.responses import JSONResponse\r\nfrom typing import Optional, List, Dict, Any\r\nfrom app.models.code_change import CodeReport\r\nfrom app.services.code_io import list_project_files, read_file, safe_path\r\nfrom app.services.trace_logger import write_code_trace\r\nfrom app.services.chat_engine import llm_local\r\nfrom app.services.memory import add_many, chunk_text, search_memory\r\n\r\nrouter = APIRouter(tags=[\"code-review\"])\r\n\r\n# ----- lecture projet -----\r\n@router.get(\"/code/files\")\r\ndef code_files(start: str = \"app\"):\r\n    try:\r\n        return {\"items\": list_project_files(start)}\r\n    except Exception as e:\r\n        raise HTTPException(400, str(e))\r\n\r\n@router.get(\"/code/file\")\r\ndef code_file(path: str = Query(..., description=\"Chemin relatif (ex: app/services/search.py)\")):\r\n    try:\r\n        content = read_file(path)\r\n        return {\"path\": path, \"content\": content}\r\n    except Exception as e:\r\n      ",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 0,
        "total_chunks": 6,
        "chunk_sha": "864991069fa82a844278c6d4c676c5b42ee3caf858e3b82303d318ba6254045c"
      }
    },
    {
      "text": "ces/search.py)\")):\r\n    try:\r\n        content = read_file(path)\r\n        return {\"path\": path, \"content\": content}\r\n    except Exception as e:\r\n        raise HTTPException(400, str(e))\r\n\r\n# ----- journalisation de rapports -----\r\n@router.post(\"/report_code\")\r\ndef report_code(report: CodeReport):\r\n    payload = {\r\n        \"file_path\": report.file_path,\r\n        \"objective\": report.objective,\r\n        \"changes\": [c.model_dump() for c in report.changes],\r\n    }\r\n    res = write_code_trace(\r\n        code=f\"[CODE-REPORT] {payload}\",\r\n        source=\"code_review/report_code\",\r\n        meta={\"file\": report.file_path}\r\n    )\r\n    return {\"ok\": True, **res}\r\n\r\n# ----- proposition de patch par LLM -----\r\n@router.post(\"/suggest_patch\")\r\ndef suggest_patch(file_path: str, objective: str, model: Optional[str] = None):\r\n    try:\r\n        content = read_file(file_path)\r\n    except Exception as e:\r\n        raise HTTPException(400, f\"Lecture impossible: {e}\")\r\n\r\n    prompt = (\r\n        \"Tu es AssistantD",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 1,
        "total_chunks": 6,
        "chunk_sha": "38c699602f2fc7e24842fc2f590376ce79a02e516b1e1d23d85f717d32572321"
      }
    },
    {
      "text": "file(file_path)\r\n    except Exception as e:\r\n        raise HTTPException(400, f\"Lecture impossible: {e}\")\r\n\r\n    prompt = (\r\n        \"Tu es AssistantDylan. Tu vas proposer un patch complet pour le fichier ci-dessous.\\n\"\r\n        \"Contraintes:\\n\"\r\n        \"- Retourne UNIQUEMENT le code final pr√™t √† coller (pas d'explication).\\n\"\r\n        \"- Conserve l'API/structure existante au maximum.\\n\"\r\n        f\"- Objectif: {objective}\\n\\n\"\r\n        \"----- DEBUT FICHIER -----\\n\"\r\n        f\"{content}\\n\"\r\n        \"----- FIN FICHIER -----\\n\"\r\n        \"Propose le fichier corrig√©/complet :\\n\"\r\n    )\r\n    patch = llm_local(prompt)\r\n    res = write_code_trace(\r\n        code=patch,\r\n        source=\"code_review/suggest_patch\",\r\n        meta={\"file\": file_path, \"objective\": objective, \"model\": model or \"default\"}\r\n    )\r\n    return {\"ok\": True, \"patch\": patch, **res}\r\n\r\n# ======== NOUVEAU : INGESTION DU CODE EN MEMOIRE ========\r\n\r\n@router.post(\"/code/ingest\")\r\ndef code_ingest(\r\n    start: str = \"app\",\r\n    a",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 2,
        "total_chunks": 6,
        "chunk_sha": "81a8a2368691f50bab99225718394e867f669a0c3b26cc2f3862a7f3db8eae5f"
      }
    },
    {
      "text": "**res}\r\n\r\n# ======== NOUVEAU : INGESTION DU CODE EN MEMOIRE ========\r\n\r\n@router.post(\"/code/ingest\")\r\ndef code_ingest(\r\n    start: str = \"app\",\r\n    allow_ext: str = \".py,.js,.ts,.html,.css,.json,.md,.txt\",\r\n    chunk: int = 1000,\r\n    overlap: int = 150,\r\n    max_bytes: int = 300_000\r\n):\r\n    \"\"\"\r\n    Lit les fichiers du projet (r√©pertoire 'start'), d√©coupe le contenu en morceaux,\r\n    et stocke chaque chunk dans la m√©moire s√©mantique avec des m√©tadonn√©es.\r\n    \"\"\"\r\n    files = []\r\n    try:\r\n        files = list_project_files(start)\r\n    except Exception as e:\r\n        raise HTTPException(400, str(e))\r\n\r\n    allow = {e.strip().lower() for e in allow_ext.split(\",\") if e.strip()}\r\n    to_add: List[Dict[str, Any]] = []\r\n\r\n    for rel in files:\r\n        if allow and (safe_path(rel).suffix.lower() not in allow):\r\n            continue\r\n        try:\r\n            txt = read_file(rel, max_bytes=max_bytes)\r\n        except Exception:\r\n            continue\r\n        chunks = chunk_text(txt, chunk=",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 3,
        "total_chunks": 6,
        "chunk_sha": "38a3e6487646cd6f674779f9d0e1e16773a321dea389da7ec3900ed9119b1fe3"
      }
    },
    {
      "text": " try:\r\n            txt = read_file(rel, max_bytes=max_bytes)\r\n        except Exception:\r\n            continue\r\n        chunks = chunk_text(txt, chunk=chunk, overlap=overlap)\r\n        for i, part in enumerate(chunks):\r\n            to_add.append({\r\n                \"text\": part,\r\n                \"meta\": {\"kind\": \"code\", \"file\": rel, \"chunk\": i, \"total_chunks\": len(chunks)}\r\n            })\r\n\r\n    n = add_many(to_add)\r\n    return {\"ok\": True, \"indexed_chunks\": n, \"files_scanned\": len(files)}\r\n\r\n@router.get(\"/code/search\")\r\ndef code_search(q: str, k: int = 8):\r\n    \"\"\"\r\n    Recherche s√©mantique dans la m√©moire limit√©e aux items de type 'code'.\r\n    \"\"\"\r\n    hits = search_memory(q, k=k, filter_meta={\"kind\": \"code\"})\r\n    # Raccourci d'affichage\r\n    out = []\r\n    for h in hits:\r\n        meta = h.get(\"meta\") or {}\r\n        out.append({\r\n            \"score\": round(h[\"score\"], 4),\r\n            \"file\": meta.get(\"file\"),\r\n            \"chunk\": meta.get(\"chunk\"),\r\n            \"preview\": h[\"text\"][:3",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 4,
        "total_chunks": 6,
        "chunk_sha": "b1e28ebbc328b8ee60b4741021a22b4a7dfebb024cbe120b9e07104256e28ad0"
      }
    },
    {
      "text": "   \"score\": round(h[\"score\"], 4),\r\n            \"file\": meta.get(\"file\"),\r\n            \"chunk\": meta.get(\"chunk\"),\r\n            \"preview\": h[\"text\"][:300]\r\n        })\r\n    return {\"query\": q, \"results\": out}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\code_review.py",
        "chunk": 5,
        "total_chunks": 6,
        "chunk_sha": "b843c0586bd28a8655f354bf00227ff19516f774065b6f9526b92abfdde56380"
      }
    },
    {
      "text": "Ôªøfrom fastapi import APIRouter, Query\r\nfrom fastapi.responses import HTMLResponse, JSONResponse\r\nfrom app.services.search import (\r\n    hybrid_search, follow_and_build, rerank,\r\n    record_feedback, load_json, save_json\r\n)\r\n\r\nrouter = APIRouter()\r\n\r\n@router.get(\"/deep_search\")\r\ndef deep_search(\r\n    q: str = Query(..., min_length=2),\r\n    max_results: int = 30,\r\n    follow: bool = False,\r\n    pretty: bool = False,\r\n    personalize: bool = True\r\n):\r\n    try:\r\n        raw = hybrid_search(q, max_results=max_results)\r\n    except Exception as e:\r\n        return JSONResponse(status_code=502, content={\"error\": \"search_engine_error\", \"detail\": str(e)})\r\n\r\n    results_out = follow_and_build(raw, follow=follow)\r\n    if personalize:\r\n        results_out = rerank(results_out, query=q)\r\n\r\n    payload = {\r\n        \"query\": q,\r\n        \"results\": [it.__dict__ for it in results_out],\r\n        \"meta\": {\"count\": len(results_out), \"follow\": follow, \"personalize\": personalize}\r\n    }\r\n    return JSONRespo",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 0,
        "total_chunks": 6,
        "chunk_sha": "9c5c813946056195a5c6697e477725201ed55d712f2d421be389882cc344d974"
      }
    },
    {
      "text": "dict__ for it in results_out],\r\n        \"meta\": {\"count\": len(results_out), \"follow\": follow, \"personalize\": personalize}\r\n    }\r\n    return JSONResponse(payload, media_type=\"application/json\", status_code=200) if pretty else payload\r\n\r\n\r\n@router.post(\"/feedback\")\r\ndef feedback(url: str, liked: bool):\r\n    record_feedback(url, liked)\r\n    return {\"ok\": True, \"liked\": liked, \"url\": url}\r\n\r\n\r\n@router.get(\"/ui\", response_class=HTMLResponse)\r\ndef ui():\r\n    return \"\"\"\r\n<!doctype html><html lang=\"fr\"><head>\r\n<meta charset=\"utf-8\"><script src=\"https://cdn.tailwindcss.com\"></script>\r\n<title>Assistant IA ‚Äî Recherche</title></head>\r\n<body class=\"bg-gray-50 p-6\">\r\n<h1 class=\"text-3xl font-bold mb-4\">üîé Assistant IA ‚Äî Recherche (GPU)</h1>\r\n<div class=\"flex gap-2 mb-4\">\r\n  <input id=\"q\" class=\"border rounded px-3 py-2 w-1/2\" placeholder=\"Ex : tendances IA 2025\">\r\n  <label class=\"flex items-center gap-2\"><input id=\"follow\" type=\"checkbox\"> Suivre liens</label>\r\n  <button onclick=\"run()\" class=\"bg-in",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 1,
        "total_chunks": 6,
        "chunk_sha": "6490b70b044d1438c3b0b72bb727e6e72d0f7edf3d0bd2e742a1edbe1ec9003b"
      }
    },
    {
      "text": "s IA 2025\">\r\n  <label class=\"flex items-center gap-2\"><input id=\"follow\" type=\"checkbox\"> Suivre liens</label>\r\n  <button onclick=\"run()\" class=\"bg-indigo-600 text-white px-4 py-2 rounded\">Rechercher</button>\r\n</div>\r\n<div id=\"status\" class=\"text-sm text-gray-600 mb-2\"></div>\r\n<div id=\"results\" class=\"space-y-4\"></div>\r\n<script>\r\nasync function run(){\r\n  const q = document.getElementById('q').value.trim();\r\n  const follow = document.getElementById('follow').checked;\r\n  if(!q){ return; }\r\n  document.getElementById('status').textContent = \"Recherche en cours...\";\r\n  const res = await fetch(`/deep_search?q=${encodeURIComponent(q)}&personalize=true&follow=${follow}`);\r\n  const data = await res.json();\r\n  const wrap = document.getElementById('results'); wrap.innerHTML=\"\";\r\n  for(const r of data.results){\r\n    const d = document.createElement('div'); d.className=\"bg-white shadow p-4 rounded\";\r\n    d.innerHTML = `\r\n      <a href=\"${r.url}\" target=\"_blank\" class=\"text-xl text-indigo-700 font-s",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 2,
        "total_chunks": 6,
        "chunk_sha": "5cda6d68067924359807076b7bead2d49acd3f8d8130276a6ecddaea97e8493f"
      }
    },
    {
      "text": "div'); d.className=\"bg-white shadow p-4 rounded\";\r\n    d.innerHTML = `\r\n      <a href=\"${r.url}\" target=\"_blank\" class=\"text-xl text-indigo-700 font-semibold\">${r.title || r.url}</a><br>\r\n      <small class=\"text-gray-500\">${r.domain || \"\"}</small>\r\n      <p class=\"mt-1 text-gray-700\">${r.snippet || \"\"}</p>\r\n      <div class=\"flex gap-3 mt-2\">\r\n        <button onclick=\"fb('${r.url}',true)\" class=\"text-green-600 hover:underline\">üëç int√©ressant</button>\r\n        <button onclick=\"fb('${r.url}',false)\" class=\"text-red-600 hover:underline\">üëé sans int√©r√™t</button>\r\n      </div>`;\r\n    wrap.appendChild(d);\r\n  }\r\n  document.getElementById('status').textContent = `${data.results.length} r√©sultats`;\r\n}\r\nasync function fb(url, liked){\r\n  await fetch(`/feedback?url=${encodeURIComponent(url)}&liked=${liked}`, {method:\"POST\"});\r\n}\r\n</script>\r\n</body></html>\r\n    \"\"\"\r\n\r\n\r\n@router.get(\"/profile\", response_class=HTMLResponse)\r\ndef profile():\r\n    data = load_json(\"data/user_prefs.json\")\r\n    prefs = dat",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 3,
        "total_chunks": 6,
        "chunk_sha": "0f93ac814ec1989adfd27a588da4e604d6ce9adf3e0f08129f25cbfaa66fdd30"
      }
    },
    {
      "text": "tml>\r\n    \"\"\"\r\n\r\n\r\n@router.get(\"/profile\", response_class=HTMLResponse)\r\ndef profile():\r\n    data = load_json(\"data/user_prefs.json\")\r\n    prefs = data.get(\"preferences\", {\"boost\": [], \"ban\": []})\r\n    hist = data.get(\"history\", [])\r\n    last = \"\".join([f\"<li>{h.get('query','?')} ‚Üí {h.get('domain','')} : {h.get('title','')}</li>\" for h in hist[-10:]])\r\n    return f\"\"\"\r\n<html><body style='font-family:Arial;padding:2rem'>\r\n<h1>üß† Profil IA</h1>\r\n<h2>Sites favoris (boost)</h2><ul>{''.join(f'<li>{b}</li>' for b in prefs.get('boost', []))}</ul>\r\n<h2>Sites bannis (ban)</h2><ul>{''.join(f'<li>{b}</li>' for b in prefs.get('ban', []))}</ul>\r\n<h2>Historique r√©cent</h2><ul>{last or \"<li>(vide)</li>\"}</ul>\r\n<form method='post' action='/reset'><button type='submit'>üîÑ R√©initialiser</button></form>\r\n</body></html>\r\n    \"\"\"\r\n\r\n\r\n@router.post(\"/reset\")\r\ndef reset():\r\n    save_json(\"data/user_prefs.json\", {\"preferences\": {\"boost\": [], \"ban\": []}, \"history\": []})\r\n    return {\"ok\": True, \"msg\": \"R√©initial",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 4,
        "total_chunks": 6,
        "chunk_sha": "f0182d1c8ee808eac608afbc27fe712fbdda6ad529089c00790b2055e811f957"
      }
    },
    {
      "text": "f reset():\r\n    save_json(\"data/user_prefs.json\", {\"preferences\": {\"boost\": [], \"ban\": []}, \"history\": []})\r\n    return {\"ok\": True, \"msg\": \"R√©initialis√©\"}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\deep_search.py",
        "chunk": 5,
        "total_chunks": 6,
        "chunk_sha": "7cca0d917fabd4850e6d6b681d800f90d73f5646b9c88141a65c23acd629789f"
      }
    },
    {
      "text": "Ôªøfrom fastapi import APIRouter, HTTPException\r\nfrom datetime import datetime\r\nfrom ..models import FeedbackIn, PrefsIn\r\nfrom ..database import db\r\nfrom ..services.prefs import load_prefs\r\n\r\nrouter = APIRouter()\r\n\r\nUSER_NAME = \"Dylan\"\r\n\r\n@router.post(\"/feedback\")\r\ndef post_feedback(fb: FeedbackIn):\r\n    label = (fb.label or \"\").lower()\r\n    if label not in (\"like\", \"dislike\"):\r\n        raise HTTPException(400, \"label doit √™tre 'like' ou 'dislike'\")\r\n    conn = db()\r\n    conn.execute(\r\n        \"INSERT INTO feedback (created_at, user, url, domain, title, label) VALUES (?, ?, ?, ?, ?, ?)\",\r\n        (datetime.utcnow().isoformat(), USER_NAME, fb.url, (fb.domain or \"\"), (fb.title or \"\"), label)\r\n    )\r\n    conn.commit()\r\n    conn.close()\r\n    return {\"ok\": True}\r\n\r\n@router.get(\"/prefs\")\r\ndef get_prefs():\r\n    return load_prefs()\r\n\r\n@router.post(\"/prefs\")\r\ndef set_prefs(p: PrefsIn):\r\n    conn = db()\r\n    conn.execute(\"\"\"\r\n      UPDATE prefs SET\r\n        preferred_domains=?, blocked_domains=?, ",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\feedback.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "c71b356b9f2317ae042ce9a46646103a6c1ca3bd216c9ce1fc76b40463eb1fea"
      }
    },
    {
      "text": "\"/prefs\")\r\ndef set_prefs(p: PrefsIn):\r\n    conn = db()\r\n    conn.execute(\"\"\"\r\n      UPDATE prefs SET\r\n        preferred_domains=?, blocked_domains=?, preferred_keywords=?, blocked_keywords=?,\r\n        like_weight=?, dislike_weight=?, domain_boost=?, keyword_boost=?, strict_block=?\r\n      WHERE id=1\r\n    \"\"\", (\r\n        p.preferred_domains or \"\",\r\n        p.blocked_domains or \"\",\r\n        p.preferred_keywords or \"\",\r\n        p.blocked_keywords or \"\",\r\n        float(p.like_weight or 1.0),\r\n        float(p.dislike_weight or -1.0),\r\n        float(p.domain_boost or 0.6),\r\n        float(p.keyword_boost or 0.4),\r\n        1 if (getattr(p, \"strict_block\", False) is True) else 0\r\n    ))\r\n    conn.commit()\r\n    conn.close()\r\n    return {\"ok\": True, \"prefs\": load_prefs()}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\feedback.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "26f56c8557f5bb8e09896daa818162d676bd75a121e1c26a08ea23fd0e984743"
      }
    },
    {
      "text": "# app/routers/trace.py\r\nfrom fastapi import APIRouter\r\nfrom pydantic import BaseModel, Field\r\nfrom typing import Optional, Dict, Any\r\nfrom app.services.trace_logger import write_code_trace, read_traces\r\n\r\nrouter = APIRouter(tags=[\"trace\"])\r\n\r\nclass TraceIn(BaseModel):\r\n    code: str = Field(..., description=\"Code g√©n√©r√© (texte brut)\")\r\n    source: str = Field(default=\"manual\", description=\"Origine (ex: self_review, chat, ui)\")\r\n    meta: Optional[Dict[str, Any]] = Field(default=None, description=\"Infos libres\")\r\n\r\n@router.post(\"/log_code\")\r\ndef log_code(inp: TraceIn):\r\n    # √©criture synchrone : garantit la cr√©ation du fichier imm√©diatement\r\n    result = write_code_trace(inp.code, inp.source, inp.meta)\r\n    return result\r\n\r\n@router.get(\"/logs\")\r\ndef logs(limit: int = 100):\r\n    return {\"items\": read_traces(limit)}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\trace.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "c3b0685ea6f1f2208e922d38d98e107c2b4f812f4f31086d4f78e23968afd179"
      }
    },
    {
      "text": "Ôªøfrom fastapi import APIRouter\r\nimport requests\r\nfrom typing import Dict, Optional\r\n\r\nrouter = APIRouter()\r\nHEADERS = {\"User-Agent\": \"AssistantDylan/1.0 (+https://example.local)\"}\r\n\r\nWEATHER_DESC = {\r\n    0:\"ciel d√©gag√©\",1:\"peu nuageux\",2:\"partiellement nuageux\",3:\"couvert\",\r\n    45:\"brouillard\",48:\"brouillard givrant\",51:\"bruine faible\",53:\"bruine mod√©r√©e\",55:\"bruine forte\",\r\n    56:\"bruine vergla√ßante faible\",57:\"bruine vergla√ßante forte\",\r\n    61:\"pluie faible\",63:\"pluie mod√©r√©e\",65:\"pluie forte\",66:\"pluie vergla√ßante faible\",67:\"pluie vergla√ßante forte\",\r\n    71:\"neige faible\",73:\"neige mod√©r√©e\",75:\"neige forte\",77:\"neige en grains\",\r\n    80:\"averses faibles\",81:\"averses mod√©r√©es\",82:\"averses fortes\",\r\n    85:\"averses de neige faibles\",86:\"averses de neige fortes\",\r\n    95:\"orages\",96:\"orages avec gr√™le faible\",99:\"orages avec gr√™le forte\",\r\n}\r\ndef describe_weather(code: Optional[int]) -> str:\r\n    return WEATHER_DESC.get(code, f\"code m√©t√©o {code}\" if code is not None else \"conditi",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\weather.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "23f0639fb1f7e52041d301722f183945dc13acefa737f646cf552296bc78364f"
      }
    },
    {
      "text": "orte\",\r\n}\r\ndef describe_weather(code: Optional[int]) -> str:\r\n    return WEATHER_DESC.get(code, f\"code m√©t√©o {code}\" if code is not None else \"conditions inconnues\")\r\n\r\ndef geocode_city(city: str) -> Dict:\r\n    url = \"https://geocoding-api.open-meteo.com/v1/search\"\r\n    params = {\"name\": city, \"count\": 1, \"language\": \"fr\", \"format\": \"json\"}\r\n    r = requests.get(url, params=params, headers=HEADERS, timeout=8); r.raise_for_status()\r\n    data = r.json(); results = data.get(\"results\") or []\r\n    if not results: raise ValueError(f\"Ville introuvable: {city}\")\r\n    top = results[0]\r\n    return {\"lat\": top[\"latitude\"], \"lon\": top[\"longitude\"], \"name\": top.get(\"name\"),\r\n            \"admin1\": top.get(\"admin1\"), \"country\": top.get(\"country\")}\r\n\r\ndef open_meteo_tomorrow(lat: float, lon: float) -> Dict:\r\n    url = (\"https://api.open-meteo.com/v1/forecast\"\r\n           f\"?latitude={lat}&longitude={lon}\"\r\n           \"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode\"\r\n       ",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\weather.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "6629b938c8288ab4c38f39b723f879f40488538157c6d813c683be71ee1167ac"
      }
    },
    {
      "text": "cast\"\r\n           f\"?latitude={lat}&longitude={lon}\"\r\n           \"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode\"\r\n           \"&timezone=Europe%2FParis\")\r\n    r = requests.get(url, headers=HEADERS, timeout=8); r.raise_for_status()\r\n    return r.json()\r\n\r\n@router.get(\"/weather\")\r\ndef weather(city: str = \"Castres\"):\r\n    loc = geocode_city(city)\r\n    data = open_meteo_tomorrow(loc[\"lat\"], loc[\"lon\"])\r\n    daily = data.get(\"daily\", {})\r\n    def pick(i, key, default=None):\r\n        arr = daily.get(key) or []\r\n        return arr[i] if len(arr) > i else default\r\n    tmax = pick(1,\"temperature_2m_max\"); tmin = pick(1,\"temperature_2m_min\")\r\n    prcp = pick(1,\"precipitation_sum\"); code = pick(1,\"weathercode\")\r\n    return {\r\n        \"city\": f\"{loc['name']}, {loc['admin1']}, {loc['country']}\",\r\n        \"coords\": {\"lat\": loc[\"lat\"], \"lon\": loc[\"lon\"]},\r\n        \"tomorrow\": {\"tmin_c\": tmin, \"tmax_c\": tmax, \"precipitation_mm\": prcp,\r\n                     \"weathercode\": co",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\weather.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "340524aa0c3b6c72b596f43ff966438aef66bf1f95b7aeb7af4662ac7b806d6e"
      }
    },
    {
      "text": "oc[\"lat\"], \"lon\": loc[\"lon\"]},\r\n        \"tomorrow\": {\"tmin_c\": tmin, \"tmax_c\": tmax, \"precipitation_mm\": prcp,\r\n                     \"weathercode\": code, \"description\": describe_weather(code)}\r\n    }\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\weather.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "1b2d6398219b3c2342f13015166e0578b844dfeed9fe8fa9ed12b403193690b4"
      }
    },
    {
      "text": "Ôªøfrom fastapi import FastAPI, Query, HTTPException\r\nfrom pydantic import BaseModel\r\nfrom typing import List, Dict, Optional, Any\r\nimport requests, time, threading, json\r\nfrom urllib.parse import urlparse\r\nfrom urllib import robotparser\r\nfrom fastapi.responses import HTMLResponse, Response\r\n\r\nfrom duckduckgo_search import DDGS\r\nimport trafilatura\r\nfrom bs4 import BeautifulSoup\r\n\r\nprint(\">>> LOADED:\", __file__)\r\nUSER_NAME = \"Dylan\"\r\nHEADERS = {\"User-Agent\": \"AssistantDylan/1.0 (+https://example.local) Contact:dylan@example.local\"}\r\n\r\napp = FastAPI(title=\"Assistant de Dylan\")\r\n\r\n# ======================== Utils communs ========================\r\ndef extract_with_bs4(html: str, max_chars: int = 1600) -> str:\r\n    soup = BeautifulSoup(html, \"html.parser\")\r\n    for tag in soup([\"script\", \"style\", \"noscript\"]):\r\n        tag.decompose()\r\n    text = \" \".join(soup.get_text(separator=\" \").split())\r\n    return text[:max_chars]\r\n\r\ndef fetch_page_text(url: str, timeout: int = 8, max_chars: int = 1400",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 0,
        "total_chunks": 23,
        "chunk_sha": "0a1585485e17c62e615913fad4481894ab7eebc8c277c71e32a2fd9dc27cf41a"
      }
    },
    {
      "text": "= \" \".join(soup.get_text(separator=\" \").split())\r\n    return text[:max_chars]\r\n\r\ndef fetch_page_text(url: str, timeout: int = 8, max_chars: int = 1400) -> str:\r\n    # 1) trafilatura.fetch_url -> extract\r\n    try:\r\n        downloaded = trafilatura.fetch_url(url, timeout=timeout)\r\n        if downloaded:\r\n            txt = trafilatura.extract(downloaded) or \"\"\r\n            if txt.strip():\r\n                return txt.strip()[:max_chars]\r\n    except Exception:\r\n        pass\r\n    # 2) requests + extract + fallback BS4\r\n    try:\r\n        resp = requests.get(url, headers=HEADERS, timeout=timeout)\r\n        if resp.ok and resp.text:\r\n            txt = trafilatura.extract(resp.text) or \"\"\r\n            if txt.strip():\r\n                return txt.strip()[:max_chars]\r\n            return extract_with_bs4(resp.text, max_chars=max_chars)\r\n    except Exception:\r\n        pass\r\n    return \"\"\r\n\r\n# ======================== Routes de base ========================\r\nclass ChatIn(BaseModel):\r\n    message: str\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 1,
        "total_chunks": 23,
        "chunk_sha": "78008f61462da6957dbd4f6a28bd4fa20f85e836c53ff0a2cb7cbd55f4f98bcc"
      }
    },
    {
      "text": "tion:\r\n        pass\r\n    return \"\"\r\n\r\n# ======================== Routes de base ========================\r\nclass ChatIn(BaseModel):\r\n    message: str\r\n\r\nclass ChatOut(BaseModel):\r\n    reply: str\r\n\r\n@app.get(\"/\")\r\ndef root():\r\n    return {\"ok\": True, \"msg\": f\"Bonjour {USER_NAME}, l‚ÄôAPI est pr√™te.\"}\r\n\r\n@app.get(\"/routes\")\r\ndef routes():\r\n    return [r.path for r in app.router.routes]\r\n\r\n@app.post(\"/chat\", response_model=ChatOut)\r\ndef chat(inp: ChatIn):\r\n    return ChatOut(reply=f\"Bonjour {USER_NAME} üëã Tu as dit : ‚Äú{inp.message}‚Äù.\")\r\n\r\n# ======================== Recherche simple ========================\r\n@app.get(\"/web_fast\")\r\ndef web_fast(q: str = \"tendances IA en entreprise 2025\", max_results: int = 3):\r\n    out = []\r\n    try:\r\n        with DDGS() as ddgs:\r\n            for r in ddgs.text(q, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results):\r\n                url = r.get(\"href\") or r.get(\"url\")\r\n                if url:\r\n                    out.append({\"title\": r.get(\"title\") ",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 2,
        "total_chunks": 23,
        "chunk_sha": "33013795a1cbcb33a03e27118375167118b514b21263461b1a3213d58eca5bab"
      }
    },
    {
      "text": "=max_results):\r\n                url = r.get(\"href\") or r.get(\"url\")\r\n                if url:\r\n                    out.append({\"title\": r.get(\"title\") or \"R√©sultat\", \"url\": url})\r\n    except Exception as e:\r\n        return {\"query\": q, \"error\": str(e), \"results\": out}\r\n    return {\"query\": q, \"results\": out}\r\n\r\n@app.get(\"/web_test\")\r\ndef web_test(q: str = \"site:wikipedia.org intelligence artificielle\", max_results: int = 2):\r\n    results = []\r\n    try:\r\n        with DDGS() as ddgs:\r\n            for r in ddgs.text(q, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results):\r\n                url = r.get(\"href\") or r.get(\"url\")\r\n                if not url:\r\n                    continue\r\n                extract = fetch_page_text(url, timeout=8, max_chars=1400)\r\n                results.append({\r\n                    \"title\": r.get(\"title\") or \"R√©sultat\",\r\n                    \"url\": url,\r\n                    \"snippet\": (r.get(\"body\") or \"\")[:220],\r\n                    \"extract\": extract",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 3,
        "total_chunks": 23,
        "chunk_sha": "158058ff26f205cd235cb3e2975ab3edb8e530f2ab72544d9e7ab0e84654bf54"
      }
    },
    {
      "text": ") or \"R√©sultat\",\r\n                    \"url\": url,\r\n                    \"snippet\": (r.get(\"body\") or \"\")[:220],\r\n                    \"extract\": extract\r\n                })\r\n                time.sleep(0.4)\r\n    except Exception as e:\r\n        results.append({\"title\": \"ERREUR\", \"url\": \"\", \"snippet\": str(e), \"extract\": \"\"})\r\n    return {\"query\": q, \"results\": results}\r\n\r\n# ======================== M√©t√©o (Open-Meteo) ========================\r\nWEATHER_DESC = {\r\n    0:\"ciel d√©gag√©\",1:\"peu nuageux\",2:\"partiellement nuageux\",3:\"couvert\",\r\n    45:\"brouillard\",48:\"brouillard givrant\",51:\"bruine faible\",53:\"bruine mod√©r√©e\",55:\"bruine forte\",\r\n    56:\"bruine vergla√ßante faible\",57:\"bruine vergla√ßante forte\",\r\n    61:\"pluie faible\",63:\"pluie mod√©r√©e\",65:\"pluie forte\",66:\"pluie vergla√ßante faible\",67:\"pluie vergla√ßante forte\",\r\n    71:\"neige faible\",73:\"neige mod√©r√©e\",75:\"neige forte\",77:\"neige en grains\",\r\n    80:\"averses faibles\",81:\"averses mod√©r√©es\",82:\"averses fortes\",\r\n    85:\"averses de neige ",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 4,
        "total_chunks": 23,
        "chunk_sha": "107c4818551765da13eaac15a72ec099e750fddefd410f7a944c11578d65cec1"
      }
    },
    {
      "text": "\"neige mod√©r√©e\",75:\"neige forte\",77:\"neige en grains\",\r\n    80:\"averses faibles\",81:\"averses mod√©r√©es\",82:\"averses fortes\",\r\n    85:\"averses de neige faibles\",86:\"averses de neige fortes\",\r\n    95:\"orages\",96:\"orages avec gr√™le faible\",99:\"orages avec gr√™le forte\",\r\n}\r\ndef describe_weather(code: Optional[int]) -> str:\r\n    return WEATHER_DESC.get(code, f\"code m√©t√©o {code}\" if code is not None else \"conditions inconnues\")\r\n\r\ndef geocode_city(city: str) -> Dict:\r\n    url = \"https://geocoding-api.open-meteo.com/v1/search\"\r\n    params = {\"name\": city, \"count\": 1, \"language\": \"fr\", \"format\": \"json\"}\r\n    r = requests.get(url, params=params, headers=HEADERS, timeout=8); r.raise_for_status()\r\n    data = r.json(); results = data.get(\"results\") or []\r\n    if not results:\r\n        raise ValueError(f\"Ville introuvable: {city}\")\r\n    top = results[0]\r\n    return {\"lat\": top[\"latitude\"], \"lon\": top[\"longitude\"], \"name\": top.get(\"name\"),\r\n            \"admin1\": top.get(\"admin1\"), \"country\": top.get(\"",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 5,
        "total_chunks": 23,
        "chunk_sha": "7a6724c3125496bbb2b09e583b492e8d6f7974e76cfc7e9305647b9ffb1d4638"
      }
    },
    {
      "text": "\r\n    return {\"lat\": top[\"latitude\"], \"lon\": top[\"longitude\"], \"name\": top.get(\"name\"),\r\n            \"admin1\": top.get(\"admin1\"), \"country\": top.get(\"country\")}\r\n\r\ndef open_meteo_tomorrow(lat: float, lon: float) -> Dict:\r\n    url = (\"https://api.open-meteo.com/v1/forecast\"\r\n           f\"?latitude={lat}&longitude={lon}\"\r\n           \"&daily=temperature_2m_max,temperature_2m_min,precipitation_sum,weathercode\"\r\n           \"&timezone=Europe%2FParis\")\r\n    r = requests.get(url, headers=HEADERS, timeout=8); r.raise_for_status()\r\n    return r.json()\r\n\r\n@app.get(\"/weather\")\r\ndef weather(city: str = \"Castres\"):\r\n    loc = geocode_city(city)\r\n    data = open_meteo_tomorrow(loc[\"lat\"], loc[\"lon\"])\r\n    daily = data.get(\"daily\", {})\r\n    def pick(i, key, default=None):\r\n        arr = daily.get(key) or []\r\n        return arr[i] if len(arr) > i else default\r\n    tmax = pick(1, \"temperature_2m_max\")\r\n    tmin = pick(1, \"temperature_2m_min\")\r\n    prcp = pick(1, \"precipitation_sum\")\r\n    code = pick(1, ",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 6,
        "total_chunks": 23,
        "chunk_sha": "3724f9e65dce687dae1af3dd18e04d7e1fe95cbb87cc2d3f1ada1eeab4ca48bf"
      }
    },
    {
      "text": "ault\r\n    tmax = pick(1, \"temperature_2m_max\")\r\n    tmin = pick(1, \"temperature_2m_min\")\r\n    prcp = pick(1, \"precipitation_sum\")\r\n    code = pick(1, \"weathercode\")\r\n    return {\r\n        \"city\": f\"{loc['name']}, {loc['admin1']}, {loc['country']}\",\r\n        \"coords\": {\"lat\": loc[\"lat\"], \"lon\": loc[\"lon\"]},\r\n        \"tomorrow\": {\"tmin_c\": tmin, \"tmax_c\": tmax, \"precipitation_mm\": prcp,\r\n                     \"weathercode\": code, \"description\": describe_weather(code)}\r\n    }\r\n\r\n# ======================== Deep Search (pouss√© & responsable) ========================\r\nDEFAULT_MAX_RESULTS = 50\r\nDEFAULT_PER_DOMAIN = 5\r\nDEFAULT_DELAY_PER_DOMAIN = 1.0\r\nREQUEST_TIMEOUT = 8\r\n\r\n_robots_cache: Dict[str, Optional[robotparser.RobotFileParser]] = {}\r\n_last_access: Dict[str, float] = {}\r\n_count_per_domain: Dict[str, int] = {}\r\n_lock = threading.Lock()\r\n\r\nclass SearchResult(BaseModel):\r\n    title: Optional[str]\r\n    url: str\r\n    snippet: Optional[str]\r\n    extract: Optional[str] = None\r\n    allowed_by_ro",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 7,
        "total_chunks": 23,
        "chunk_sha": "5a8c1d7f61fb79761f2d0a5b70ab76b12cc941ef52f303c29c8e3b41ccaad668"
      }
    },
    {
      "text": "ass SearchResult(BaseModel):\r\n    title: Optional[str]\r\n    url: str\r\n    snippet: Optional[str]\r\n    extract: Optional[str] = None\r\n    allowed_by_robots: Optional[bool] = None\r\n    domain: Optional[str] = None\r\n\r\nclass DeepSearchOut(BaseModel):\r\n    query: str\r\n    results: List[SearchResult]\r\n    meta: Dict[str, Any]\r\n\r\ndef get_domain(url: str) -> str:\r\n    try:\r\n        return urlparse(url).netloc.lower()\r\n    except Exception:\r\n        return \"\"\r\n\r\ndef can_fetch_url(url: str, user_agent: str = HEADERS[\"User-Agent\"]) -> bool:\r\n    domain = get_domain(url)\r\n    if not domain:\r\n        return False\r\n    base = f\"{urlparse(url).scheme}://{domain}\"\r\n    rp = _robots_cache.get(base)\r\n    if rp is None:\r\n        rp = robotparser.RobotFileParser()\r\n        try:\r\n            rp.set_url(base + \"/robots.txt\")\r\n            rp.read()\r\n            _robots_cache[base] = rp\r\n        except Exception:\r\n            _robots_cache[base] = None\r\n            return True\r\n    if rp is None:\r\n        ret",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 8,
        "total_chunks": 23,
        "chunk_sha": "0e50334f8d5a9fe7506e2a9fd47db52600bd3eedc647c1e7e1ca3ba488bd0edc"
      }
    },
    {
      "text": " _robots_cache[base] = rp\r\n        except Exception:\r\n            _robots_cache[base] = None\r\n            return True\r\n    if rp is None:\r\n        return True\r\n    return rp.can_fetch(user_agent, url)\r\n\r\ndef polite_wait(domain: str, min_interval: float = DEFAULT_DELAY_PER_DOMAIN):\r\n    with _lock:\r\n        last = _last_access.get(domain)\r\n        now = time.time()\r\n        if last:\r\n            wait = min_interval - (now - last)\r\n            if wait > 0:\r\n                time.sleep(wait)\r\n        _last_access[domain] = time.time()\r\n\r\ndef increment_domain_count(domain: str) -> int:\r\n    with _lock:\r\n        c = _count_per_domain.get(domain, 0) + 1\r\n        _count_per_domain[domain] = c\r\n        return c\r\n\r\ndef fetch_metadata(url: str) -> Dict[str, Optional[str]]:\r\n    resp = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)\r\n    resp.raise_for_status()\r\n    html = resp.text\r\n    # trafilatura extract\r\n    try:\r\n        txt = trafilatura.extract(html) or \"\"\r\n        extract = \"",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 9,
        "total_chunks": 23,
        "chunk_sha": "f0ea48bfc9e542ceba761f915bc84284251655124f6afd827c0f36c6a0145701"
      }
    },
    {
      "text": "resp.raise_for_status()\r\n    html = resp.text\r\n    # trafilatura extract\r\n    try:\r\n        txt = trafilatura.extract(html) or \"\"\r\n        extract = \" \".join(txt.split())[:500] if txt and len(txt.strip()) > 40 else \"\"\r\n    except Exception:\r\n        extract = \"\"\r\n    # title + meta description\r\n    soup = BeautifulSoup(html, \"html.parser\")\r\n    title_tag = soup.find(\"title\")\r\n    title = title_tag.get_text(strip=True) if title_tag else None\r\n    meta = soup.find(\"meta\", attrs={\"name\": \"description\"}) or soup.find(\"meta\", attrs={\"property\": \"og:description\"})\r\n    snippet = meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\r\n    if not snippet and not extract:\r\n        node = soup.find(\"p\")\r\n        if node and node.get_text(strip=True):\r\n            snippet = node.get_text(strip=True)[:300]\r\n    return {\"title\": title, \"snippet\": snippet, \"extract\": extract}\r\n\r\ndef ddg_search_raw(query: str, max_results: int = 50) -> List[Dict]:\r\n    results = []\r\n    with DDGS() as ",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 10,
        "total_chunks": 23,
        "chunk_sha": "02f89491d8878af85a55d8fb9f8ce451bff4e9eea79310bb79de5fff0284e56b"
      }
    },
    {
      "text": "\"snippet\": snippet, \"extract\": extract}\r\n\r\ndef ddg_search_raw(query: str, max_results: int = 50) -> List[Dict]:\r\n    results = []\r\n    with DDGS() as ddgs:\r\n        for r in ddgs.text(query, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results):\r\n            results.append(r)\r\n    return results\r\n\r\n@app.get(\"/deep_search\", response_model=DeepSearchOut)\r\ndef deep_search(\r\n    q: str = Query(..., min_length=2),\r\n    max_results: int = Query(DEFAULT_MAX_RESULTS, ge=1, le=200),\r\n    follow: bool = Query(False),\r\n    max_per_domain: int = Query(DEFAULT_PER_DOMAIN, ge=1, le=50),\r\n    delay_per_domain: float = Query(DEFAULT_DELAY_PER_DOMAIN, ge=0.0, le=10.0),\r\n    pretty: bool = Query(False)\r\n):\r\n    if not q or len(q.strip()) < 2:\r\n        raise HTTPException(status_code=400, detail=\"Query trop courte\")\r\n    max_results = min(max_results, 200)\r\n\r\n    try:\r\n        raw = ddg_search_raw(q, max_results=max_results)\r\n    except Exception as e:\r\n        raise HTTPException(status_code=5",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 11,
        "total_chunks": 23,
        "chunk_sha": "dcc2f6ef7b5b3da015c3d853b40010381d1a96db0661e5a281aac845ab05707d"
      }
    },
    {
      "text": "lts, 200)\r\n\r\n    try:\r\n        raw = ddg_search_raw(q, max_results=max_results)\r\n    except Exception as e:\r\n        raise HTTPException(status_code=500, detail=f\"Erreur moteur: {e}\")\r\n\r\n    results_out: List[SearchResult] = []\r\n    total_followed = 0\r\n    domain_counts_local: Dict[str, int] = {}\r\n\r\n    for r in raw:\r\n        url = r.get(\"href\") or r.get(\"url\")\r\n        title = r.get(\"title\") or None\r\n        snippet_from_search = (r.get(\"body\") or \"\")[:300] or None\r\n        if not url:\r\n            continue\r\n\r\n        domain = get_domain(url)\r\n        allowed = can_fetch_url(url)\r\n\r\n        item = SearchResult(\r\n            title=title, url=url, snippet=snippet_from_search,\r\n            extract=None, allowed_by_robots=allowed, domain=domain\r\n        )\r\n\r\n        if follow and allowed:\r\n            if domain_counts_local.get(domain, 0) < max_per_domain:\r\n                polite_wait(domain, min_interval=delay_per_domain)\r\n                c = increment_domain_count(domain)\r\n             ",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 12,
        "total_chunks": 23,
        "chunk_sha": "df11088f8a0a093528c6cb610b06a1d341577f2a6464fea5624459e432aa2b00"
      }
    },
    {
      "text": "max_per_domain:\r\n                polite_wait(domain, min_interval=delay_per_domain)\r\n                c = increment_domain_count(domain)\r\n                if c <= max_per_domain:\r\n                    try:\r\n                        meta = fetch_metadata(url)\r\n                        item.title = item.title or meta.get(\"title\")\r\n                        item.snippet = item.snippet or meta.get(\"snippet\")\r\n                        item.extract = meta.get(\"extract\") or None\r\n                        total_followed += 1\r\n                    except Exception as e:\r\n                        item.extract = f\"ERROR_FETCH:{str(e)}\"\r\n                domain_counts_local[domain] = domain_counts_local.get(domain, 0) + 1\r\n\r\n        results_out.append(item)\r\n        if len(results_out) >= max_results:\r\n            break\r\n\r\n    meta = {\r\n        \"total_results_from_search\": len(raw),\r\n        \"returned_results\": len(results_out),\r\n        \"follow_performed\": follow,\r\n        \"total_followed\": total_followed,\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 13,
        "total_chunks": 23,
        "chunk_sha": "fa6358a71b5ca0e50217ad19ab94c3584fa040c25978ac60cd435e10b6a8fff5"
      }
    },
    {
      "text": "om_search\": len(raw),\r\n        \"returned_results\": len(results_out),\r\n        \"follow_performed\": follow,\r\n        \"total_followed\": total_followed,\r\n        \"max_per_domain\": max_per_domain,\r\n        \"delay_per_domain\": delay_per_domain,\r\n    }\r\n\r\n    result = {\"query\": q, \"results\": results_out, \"meta\": meta}\r\n\r\n    if pretty:\r\n        return Response(\r\n            content=json.dumps(result, ensure_ascii=False, indent=2),\r\n            media_type=\"application/json\",\r\n        )\r\n    return result\r\n\r\n# ======================== UI (barre de recherche) ========================\r\n@app.get(\"/ui\", response_class=HTMLResponse)\r\ndef ui():\r\n    return \"\"\"\r\n<!doctype html>\r\n<html lang=\"fr\">\r\n<head>\r\n  <meta charset=\"utf-8\" />\r\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n  <title>Assistant de Dylan ‚Äî Deep Search</title>\r\n  <script src=\"https://cdn.tailwindcss.com\"></script>\r\n  <style>\r\n    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, \"Li",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 14,
        "total_chunks": 23,
        "chunk_sha": "afcc129f671dfd717139ed4e90d2c9f320e3b65cf3925728c4c73fa910fc0a80"
      }
    },
    {
      "text": "\n  <script src=\"https://cdn.tailwindcss.com\"></script>\r\n  <style>\r\n    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, \"Liberation Mono\", monospace; }\r\n    .card { border-radius: 1rem; box-shadow: 0 6px 24px rgba(0,0,0,.08); }\r\n  </style>\r\n</head>\r\n<body class=\"bg-gray-50 text-gray-900\">\r\n  <div class=\"max-w-5xl mx-auto p-6\">\r\n    <h1 class=\"text-2xl font-semibold mb-4\">üîé Assistant de Dylan ‚Äî Deep Search</h1>\r\n\r\n    <div class=\"card bg-white p-4 mb-6\">\r\n      <div class=\"grid grid-cols-1 md:grid-cols-6 gap-3 items-end\">\r\n        <div class=\"md:col-span-3\">\r\n          <label class=\"block text-sm mb-1\">Requ√™te</label>\r\n          <input id=\"q\" type=\"text\" placeholder=\"ex: tendances IA en entreprise 2025\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Max r√©sultats</label>\r\n          <input id=\"max_results\" type=\"number",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 15,
        "total_chunks": 23,
        "chunk_sha": "c7ac5d66be89053a84274adf50ce32dc546abacef6f77aede563d172ffc408fc"
      }
    },
    {
      "text": "\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Max r√©sultats</label>\r\n          <input id=\"max_results\" type=\"number\" min=\"1\" max=\"200\" value=\"30\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Max/domain</label>\r\n          <input id=\"max_per_domain\" type=\"number\" min=\"1\" max=\"50\" value=\"3\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Delay/domain (s)</label>\r\n          <input id=\"delay_per_domain\" type=\"number\" step=\"0.1\" min=\"0\" max=\"10\" value=\"1.2\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div class=\"flex items-center gap-3\">\r\n          <label class=\"inline-flex it",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 16,
        "total_chunks": 23,
        "chunk_sha": "1fb2e0e6ed9fa83e08329ae967ceb8158556081cc153f02507b3f0d0749c56d2"
      }
    },
    {
      "text": "tline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div class=\"flex items-center gap-3\">\r\n          <label class=\"inline-flex items-center gap-2\">\r\n            <input id=\"follow\" type=\"checkbox\" class=\"h-4 w-4\" />\r\n            <span>Suivre liens</span>\r\n          </label>\r\n          <label class=\"inline-flex items-center gap-2\">\r\n            <input id=\"pretty\" type=\"checkbox\" class=\"h-4 w-4\" />\r\n            <span>JSON joli</span>\r\n          </label>\r\n        </div>\r\n        <div class=\"md:col-span-6 flex gap-3\">\r\n          <button id=\"go\" class=\"rounded-lg bg-indigo-600 text-white px-4 py-2 hover:bg-indigo-700\">\r\n            Rechercher\r\n          </button>\r\n          <button id=\"clear\" class=\"rounded-lg bg-gray-200 text-gray-800 px-4 py-2 hover:bg-gray-300\">\r\n            Effacer\r\n          </button>\r\n        </div>\r\n      </div>\r\n    </div>\r\n\r\n    <div id=\"status\" class=\"text-sm text-gray-600 mb-3\"></div>\r\n    <div id=\"results\" class=\"space-y-4\"></div>\r\n\r\n    <det",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 17,
        "total_chunks": 23,
        "chunk_sha": "f78eb3bd02fc37ebb57cd4b2dedc1939334fb6b984da171f8ec5e9b30ba664fa"
      }
    },
    {
      "text": "      </div>\r\n    </div>\r\n\r\n    <div id=\"status\" class=\"text-sm text-gray-600 mb-3\"></div>\r\n    <div id=\"results\" class=\"space-y-4\"></div>\r\n\r\n    <details class=\"mt-8\">\r\n      <summary class=\"cursor-pointer text-sm text-gray-600\">Voir la r√©ponse JSON brute</summary>\r\n      <pre id=\"raw\" class=\"mono text-xs bg-white p-4 rounded-lg overflow-auto mt-2\"></pre>\r\n    </details>\r\n  </div>\r\n\r\n<script>\r\nconst $ = (sel) => document.querySelector(sel);\r\nconst esc = (s) => (s || \"\").toString().replace(/[&<>]/g, c => ({'&':'&amp;','<':'&lt;','>':'&gt;'}[c]) );\r\n\r\nasync function run() {\r\n  const q = $(\"#q\").value.trim();\r\n  if (!q) { $(\"#status\").textContent = \"Saisis une requ√™te.\"; return; }\r\n\r\n  const max_results = +$(\"#max_results\").value || 30;\r\n  const follow = $(\"#follow\").checked;\r\n  const max_per_domain = +$(\"#max_per_domain\").value || 3;\r\n  const delay_per_domain = +$(\"#delay_per_domain\").value || 1.2;\r\n  const pretty = $(\"#pretty\").checked;\r\n\r\n  const params = new URLSearchParams({\r\n    q,",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 18,
        "total_chunks": 23,
        "chunk_sha": "dc4b7cd7361cb1cbbaee1a6b361c6410d1f5ea739ab8e18fa26943ee01e2217c"
      }
    },
    {
      "text": "nst delay_per_domain = +$(\"#delay_per_domain\").value || 1.2;\r\n  const pretty = $(\"#pretty\").checked;\r\n\r\n  const params = new URLSearchParams({\r\n    q, max_results, follow, max_per_domain, delay_per_domain, pretty\r\n  });\r\n\r\n  const url = `/deep_search?${params.toString()}`;\r\n  $(\"#status\").textContent = \"Recherche en cours‚Ä¶\";\r\n  $(\"#results\").innerHTML = \"\";\r\n  $(\"#raw\").textContent = \"\";\r\n\r\n  try {\r\n    const res = await fetch(url);\r\n    const txt = await res.text();\r\n\r\n    let data;\r\n    try { data = JSON.parse(txt); } catch { data = null; }\r\n\r\n    if (data && data.results) {\r\n      renderCards(data);\r\n      $(\"#raw\").textContent = JSON.stringify(data, null, 2);\r\n      $(\"#status\").textContent = `OK ‚Äî ${data.results.length} r√©sultats (follow=${data.meta.follow_performed ? \"oui\" : \"non\"})`;\r\n    } else {\r\n      $(\"#raw\").textContent = txt;\r\n      $(\"#status\").textContent = \"R√©ponse format√©e (pretty)\";\r\n    }\r\n  } catch (e) {\r\n    $(\"#status\").textContent = \"Erreur: \" + e.message;\r\n  }\r",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 19,
        "total_chunks": 23,
        "chunk_sha": "62e209cef4ac3fe27fa6e6a31c7f15c30f3f2560a5fb0abb8be5c9c0584bbf91"
      }
    },
    {
      "text": ";\r\n      $(\"#status\").textContent = \"R√©ponse format√©e (pretty)\";\r\n    }\r\n  } catch (e) {\r\n    $(\"#status\").textContent = \"Erreur: \" + e.message;\r\n  }\r\n}\r\n\r\nfunction renderCards(data) {\r\n  const wrap = $(\"#results\");\r\n  wrap.innerHTML = \"\";\r\n  for (const it of data.results) {\r\n    const allowed = it.allowed_by_robots === false\r\n      ? '<span class=\"text-xs bg-red-100 text-red-700 px-2 py-1 rounded-full\">robots.txt: non</span>'\r\n      : '<span class=\"text-xs bg-green-100 text-green-700 px-2 py-1 rounded-full\">robots.txt: ok</span>';\r\n\r\n    const card = document.createElement(\"div\");\r\n    card.className = \"card bg-white p-4\";\r\n    card.innerHTML = `\r\n      <div class=\"flex flex-wrap items-center gap-2 mb-2\">\r\n        <a class=\"text-lg font-medium text-indigo-700 hover:underline\" href=\"${esc(it.url)}\" target=\"_blank\" rel=\"noopener\">\r\n          ${esc(it.title || it.url)}\r\n        </a>\r\n        <span class=\"text-xs bg-gray-100 text-gray-700 px-2 py-1 rounded-full\">${esc(it.domain || \"\")}</s",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 20,
        "total_chunks": 23,
        "chunk_sha": "7e81a1d88db34a1c1f45473016091ca6a8b146d31ea08ab4e50022c422a7df7a"
      }
    },
    {
      "text": "   ${esc(it.title || it.url)}\r\n        </a>\r\n        <span class=\"text-xs bg-gray-100 text-gray-700 px-2 py-1 rounded-full\">${esc(it.domain || \"\")}</span>\r\n        ${allowed}\r\n      </div>\r\n      ${it.snippet ? `<p class=\"text-sm text-gray-700 mb-2\">${esc(it.snippet)}</p>` : ``}\r\n      ${it.extract ? `<details class=\"mt-1\">\r\n          <summary class=\"text-sm text-gray-600 cursor-pointer\">Extrait</summary>\r\n          <p class=\"text-sm text-gray-800 mt-1\">${esc(it.extract)}</p>\r\n      </details>` : ``}\r\n      <div class=\"mt-2 text-xs text-gray-500 mono\">${esc(it.url)}</div>\r\n    `;\r\n    wrap.appendChild(card);\r\n  }\r\n}\r\n\r\ndocument.addEventListener(\"DOMContentLoaded\", () => {\r\n  $(\"#go\").addEventListener(\"click\", run);\r\n  $(\"#clear\").addEventListener(\"click\", () => {\r\n    $(\"#q\").value = \"\";\r\n    $(\"#results\").innerHTML = \"\";\r\n    $(\"#raw\").textContent = \"\";\r\n    $(\"#status\").textContent = \"\";\r\n  });\r\n  $(\"#q\").addEventListener(\"keydown\", (e) => { if (e.key === \"Enter\") run(); });\r\n});\r\n</",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 21,
        "total_chunks": 23,
        "chunk_sha": "346f261c9469d7a19fd9b8f16bf4469ac311523f4a2a238a21ba6d1c21d8e757"
      }
    },
    {
      "text": "extContent = \"\";\r\n    $(\"#status\").textContent = \"\";\r\n  });\r\n  $(\"#q\").addEventListener(\"keydown\", (e) => { if (e.key === \"Enter\") run(); });\r\n});\r\n</script>\r\n</body>\r\n</html>\r\n    \"\"\"\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\server.py",
        "chunk": 22,
        "total_chunks": 23,
        "chunk_sha": "ec27ad7befd003af31cb6de9125218a4b1694d650c224aa6641165aaef29becd"
      }
    },
    {
      "text": "Ôªøfrom fastapi import FastAPI\r\nprint('>>> LOADED (min):', __file__)\r\napp = FastAPI(title='Smoke Test')\r\n@app.get('/')\r\ndef root():\r\n    return {'ok': True, 'msg': 'root ok'}\r\n@app.get('/routes')\r\ndef routes():\r\n    return [r.path for r in app.router.routes]\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\server_min.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "97bf8fe4b3c1ff9d0ab1260de70ead156a81329a9d27a6e23fb7c5bce40e682a"
      }
    },
    {
      "text": "\"\"\"\r\nserver_search.py\r\nEndpoint responsable pour recherche \"pouss√©e\" :\r\n- /deep_search?q=...&max_results=50&follow=true\r\n- Respecte robots.txt, rate-limit par domaine, plafond par domaine, d√©lai global.\r\n\"\"\"\r\n\r\nfrom fastapi import FastAPI, Query, HTTPException\r\nfrom pydantic import BaseModel\r\nfrom typing import List, Optional, Dict, Any\r\nfrom duckduckgo_search import DDGS\r\nfrom urllib.parse import urlparse\r\nfrom urllib import robotparser\r\nimport requests\r\nimport time\r\nimport trafilatura\r\nfrom bs4 import BeautifulSoup\r\nimport threading\r\n\r\n# ---------- Configurable ----------\r\nUSER_AGENT = \"AssistantDylan/1.0 (+https://example.local contact:dylan@example.local)\"\r\nDEFAULT_MAX_RESULTS = 50           # plafond global (ne pas trop pousser)\r\nDEFAULT_PER_DOMAIN = 5             # max pages suivies par domaine\r\nDEFAULT_DELAY_PER_DOMAIN = 1.0     # secondes entre requ√™tes sur le m√™me domaine\r\nREQUEST_TIMEOUT = 8                # timeout HTTP\r\n# ----------------------------------\r\n\r\napp = FastAPI(",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 0,
        "total_chunks": 11,
        "chunk_sha": "5b4a261c68ca3d450579a5b340d7aafec72e74ebcf0d8c5adc14ad4d916816ee"
      }
    },
    {
      "text": "secondes entre requ√™tes sur le m√™me domaine\r\nREQUEST_TIMEOUT = 8                # timeout HTTP\r\n# ----------------------------------\r\n\r\napp = FastAPI(title=\"Assistant Search (pouss√© et responsable)\")\r\n\r\n# In-memory caches / counters (process-local)\r\n_robots_cache: Dict[str, Optional[robotparser.RobotFileParser]] = {}\r\n_last_access: Dict[str, float] = {}\r\n_count_per_domain: Dict[str, int] = {}\r\n_lock = threading.Lock()  # prot√®ge _last_access et _count_per_domain\r\n\r\n# ---------- Models ----------\r\nclass SearchResult(BaseModel):\r\n    title: Optional[str]\r\n    url: str\r\n    snippet: Optional[str]\r\n    extract: Optional[str] = None  # petit extrait si follow True\r\n    allowed_by_robots: Optional[bool] = None\r\n    domain: Optional[str] = None\r\n\r\nclass DeepSearchOut(BaseModel):\r\n    query: str\r\n    results: List[SearchResult]\r\n    meta: Dict[str, Any]\r\n\r\n# ---------- Polite helpers ----------\r\ndef get_domain(url: str) -> str:\r\n    try:\r\n        p = urlparse(url)\r\n        return p.netloc.lowe",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 1,
        "total_chunks": 11,
        "chunk_sha": "1df8c7f61d7590d0b98c919d63a1042c6e415d0c9c30ad92e63af1a129c1a21b"
      }
    },
    {
      "text": "r, Any]\r\n\r\n# ---------- Polite helpers ----------\r\ndef get_domain(url: str) -> str:\r\n    try:\r\n        p = urlparse(url)\r\n        return p.netloc.lower()\r\n    except Exception:\r\n        return \"\"\r\n\r\ndef can_fetch_url(url: str, user_agent: str = USER_AGENT) -> bool:\r\n    domain = get_domain(url)\r\n    if not domain:\r\n        return False\r\n    base = f\"{urlparse(url).scheme}://{domain}\"\r\n    rp = _robots_cache.get(base)\r\n    if rp is None:\r\n        rp = robotparser.RobotFileParser()\r\n        try:\r\n            rp.set_url(base + \"/robots.txt\")\r\n            rp.read()\r\n            _robots_cache[base] = rp\r\n        except Exception:\r\n            # si robots.txt non disponible, on choisit la posture prudente : permettre mais avec limites appliqu√©es\r\n            _robots_cache[base] = None\r\n            return True\r\n    if rp is None:\r\n        return True\r\n    return rp.can_fetch(user_agent, url)\r\n\r\ndef polite_wait(domain: str, min_interval: float = DEFAULT_DELAY_PER_DOMAIN):\r\n    with _lock:\r\n   ",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 2,
        "total_chunks": 11,
        "chunk_sha": "4fe181eba6696b308278711264407472ca0f14fa108041f4e255b6d9b9291062"
      }
    },
    {
      "text": " True\r\n    return rp.can_fetch(user_agent, url)\r\n\r\ndef polite_wait(domain: str, min_interval: float = DEFAULT_DELAY_PER_DOMAIN):\r\n    with _lock:\r\n        last = _last_access.get(domain)\r\n        now = time.time()\r\n        if last:\r\n            wait = min_interval - (now - last)\r\n            if wait > 0:\r\n                time.sleep(wait)\r\n        _last_access[domain] = time.time()\r\n\r\ndef increment_domain_count(domain: str) -> int:\r\n    with _lock:\r\n        c = _count_per_domain.get(domain, 0) + 1\r\n        _count_per_domain[domain] = c\r\n        return c\r\n\r\n# ---------- Fetch minimal metadata (title + meta description or first text snippet) ----------\r\ndef fetch_metadata(url: str) -> Dict[str, Optional[str]]:\r\n    \"\"\"\r\n    R√©cup√®re en mode poli : title, meta description, extrait court.\r\n    Respecte timeout et user-agent. N'essaie pas d'extraire tout le site.\r\n    \"\"\"\r\n    headers = {\"User-Agent\": USER_AGENT}\r\n    resp = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\r\n    re",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 3,
        "total_chunks": 11,
        "chunk_sha": "3a548f7f79e5a8f6efa2b9e998d926e0d5a6d2392b4c7e6d3a6e51becf214d1f"
      }
    },
    {
      "text": "raire tout le site.\r\n    \"\"\"\r\n    headers = {\"User-Agent\": USER_AGENT}\r\n    resp = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)\r\n    resp.raise_for_status()\r\n    html = resp.text\r\n\r\n    # 1) essayer trafilatura (souvent meilleur pour contenu principal)\r\n    try:\r\n        txt = trafilatura.extract(html) or \"\"\r\n        if txt and len(txt.strip()) > 40:\r\n            # retourner un d√©but lisible\r\n            extract = \" \".join(txt.strip().split())[:500]\r\n        else:\r\n            extract = \"\"\r\n    except Exception:\r\n        extract = \"\"\r\n\r\n    # 2) r√©cup√©rer title + meta description via BeautifulSoup (rapide)\r\n    soup = BeautifulSoup(html, \"html.parser\")\r\n    title_tag = soup.find(\"title\")\r\n    title = title_tag.get_text(strip=True) if title_tag else None\r\n    meta = soup.find(\"meta\", attrs={\"name\":\"description\"}) or soup.find(\"meta\", attrs={\"property\":\"og:description\"})\r\n    snippet = meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\r\n\r\n    # fallback ",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 4,
        "total_chunks": 11,
        "chunk_sha": "9249a1e121f0c07639073dafb3d1ec16dab889940c3ba20c5621f0f6bf764c17"
      }
    },
    {
      "text": "d(\"meta\", attrs={\"property\":\"og:description\"})\r\n    snippet = meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\r\n\r\n    # fallback snippet to first text excerpt (small)\r\n    if not snippet and not extract:\r\n        # take some visible text\r\n        for sel in [\"p\", \"h1\", \"h2\", \"article\"]:\r\n            node = soup.find(sel)\r\n            if node and node.get_text(strip=True):\r\n                snippet = node.get_text(strip=True)[:300]\r\n                break\r\n\r\n    return {\"title\": title, \"snippet\": snippet, \"extract\": extract}\r\n\r\n# ---------- Core: perform search (links from DDG) ----------\r\ndef ddg_search_raw(query: str, max_results: int = 50) -> List[Dict]:\r\n    \"\"\"Retourne la liste brute dicts depuis duckduckgo_search (title, href, body...).\"\"\"\r\n    results = []\r\n    with DDGS() as ddgs:\r\n        for r in ddgs.text(query, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results):\r\n            results.append(r)\r\n    return results\r\n\r\n# ---------- Endpoint princi",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 5,
        "total_chunks": 11,
        "chunk_sha": "e55018ab9291d3c0e0b1fc8698568ac768fefcc7a4bafbc12f561bec3d70a590"
      }
    },
    {
      "text": "y, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results):\r\n            results.append(r)\r\n    return results\r\n\r\n# ---------- Endpoint principal ----------\r\n@app.get(\"/deep_search\", response_model=DeepSearchOut)\r\ndef deep_search(\r\n    q: str = Query(..., min_length=2, description=\"Requ√™te de recherche\"),\r\n    max_results: int = Query(DEFAULT_MAX_RESULTS, ge=1, le=200, description=\"Nombre maximum de r√©sultats (global)\"),\r\n    follow: bool = Query(False, description=\"Si true, on suit chaque lien (poliment) et r√©cup√®re titre/snippet/extract\"),\r\n    max_per_domain: int = Query(DEFAULT_PER_DOMAIN, ge=1, le=50, description=\"Max pages suivies par domaine\"),\r\n    delay_per_domain: float = Query(DEFAULT_DELAY_PER_DOMAIN, ge=0.0, le=10.0, description=\"D√©lai minimum (s) entre requ√™tes sur un m√™me domaine\")\r\n):\r\n    # v√©rifications basiques\r\n    if not q or len(q.strip()) < 2:\r\n        raise HTTPException(status_code=400, detail=\"Query trop courte\")\r\n    max_results = min(max_results, 200",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 6,
        "total_chunks": 11,
        "chunk_sha": "c9752fa3b856b237dfb039c091866d63d458dc0f32dd734704785c1888b9e525"
      }
    },
    {
      "text": "\n    if not q or len(q.strip()) < 2:\r\n        raise HTTPException(status_code=400, detail=\"Query trop courte\")\r\n    max_results = min(max_results, 200)\r\n\r\n    # Step 1: obtenir les r√©sultats du moteur (liens)\r\n    try:\r\n        raw = ddg_search_raw(q, max_results=max_results)\r\n    except Exception as e:\r\n        raise HTTPException(status_code=500, detail=f\"Erreur moteur: {e}\")\r\n\r\n    results_out: List[SearchResult] = []\r\n    total_followed = 0\r\n    domain_counts_local: Dict[str, int] = {}\r\n\r\n    # Step 2: parcourir les r√©sultats, optionnellement suivre\r\n    for r in raw:\r\n        url = r.get(\"href\") or r.get(\"url\")\r\n        title = r.get(\"title\") or None\r\n        snippet_from_search = (r.get(\"body\") or \"\")[:300] or None\r\n        if not url:\r\n            continue\r\n\r\n        domain = get_domain(url)\r\n        allowed = can_fetch_url(url)\r\n\r\n        item = SearchResult(\r\n            title=title,\r\n            url=url,\r\n            snippet=snippet_from_search,\r\n            extract=None,\r\n  ",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 7,
        "total_chunks": 11,
        "chunk_sha": "df5a2aa390f4004bb78a952038139caa3b4205ea068de4bdf8922c343749b65a"
      }
    },
    {
      "text": "\n        item = SearchResult(\r\n            title=title,\r\n            url=url,\r\n            snippet=snippet_from_search,\r\n            extract=None,\r\n            allowed_by_robots=allowed,\r\n            domain=domain\r\n        )\r\n\r\n        # if follow requested and allowed and we haven't exceeded per-domain caps:\r\n        if follow and allowed:\r\n            # per-domain counting\r\n            domain_count = domain_counts_local.get(domain, 0)\r\n            if domain_count >= max_per_domain:\r\n                # skip following this domain further\r\n                item.extract = None\r\n            else:\r\n                # wait politly\r\n                polite_wait(domain, min_interval=delay_per_domain)\r\n                # re-check global/process-level per-domain count\r\n                c = increment_domain_count(domain)\r\n                if c > max_per_domain:\r\n                    # exceeded global process limit for this domain\r\n                    item.extract = None\r\n                else:\r\n         ",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 8,
        "total_chunks": 11,
        "chunk_sha": "f66ef1da87d89ddade0c8588ff884d82f847531ec44fddf31b4bf078c1c94642"
      }
    },
    {
      "text": "omain:\r\n                    # exceeded global process limit for this domain\r\n                    item.extract = None\r\n                else:\r\n                    # attempt fetch metadata, protected by try/except\r\n                    try:\r\n                        meta = fetch_metadata(url)\r\n                        item.title = item.title or meta.get(\"title\")\r\n                        item.snippet = item.snippet or meta.get(\"snippet\")\r\n                        # prefer trafilatura extract if available\r\n                        item.extract = meta.get(\"extract\") or None\r\n                        total_followed += 1\r\n                    except Exception as e:\r\n                        # don't stop the whole pipeline; log in extract\r\n                        item.extract = f\"ERROR_FETCH:{str(e)}\"\r\n                domain_counts_local[domain] = domain_counts_local.get(domain, 0) + 1\r\n\r\n        results_out.append(item)\r\n\r\n        # stop early if we've already processed enough raw results (respect max",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 9,
        "total_chunks": 11,
        "chunk_sha": "1d00e131831a0a068ec533ca4599ee5112af3bdd2736e47151c988ee73279649"
      }
    },
    {
      "text": "counts_local.get(domain, 0) + 1\r\n\r\n        results_out.append(item)\r\n\r\n        # stop early if we've already processed enough raw results (respect max_results)\r\n        if len(results_out) >= max_results:\r\n            break\r\n\r\n    meta = {\r\n        \"total_results_from_search\": len(raw),\r\n        \"returned_results\": len(results_out),\r\n        \"follow_performed\": follow,\r\n        \"total_followed\": total_followed,\r\n        \"max_per_domain\": max_per_domain,\r\n        \"delay_per_domain\": delay_per_domain\r\n    }\r\n\r\n    return DeepSearchOut(query=q, results=results_out, meta=meta)\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\server_search.py",
        "chunk": 10,
        "total_chunks": 11,
        "chunk_sha": "1d5126e2acbd93f2bd571a72be6dccbaec31d549856f2c3d23f7c717d4def9ab"
      }
    },
    {
      "text": "Ôªø\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\__init__.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "f01a374e9c81e3db89b3a42940c4d6a5447684986a1296e42bf13f196eed6295"
      }
    },
    {
      "text": "# app/services/code_io.py\r\nfrom pathlib import Path\r\nfrom typing import List\r\n\r\nPROJECT_ROOT = Path(__file__).resolve().parents[2]  # racine: dossier assistantia/\r\nALLOW_EXT = {\".py\", \".txt\", \".md\", \".json\", \".html\", \".js\", \".css\"}\r\n\r\ndef safe_path(rel_path: str) -> Path:\r\n    \"\"\"Retourne un Path s√©curis√©, emp√™chant la sortie de la racine projet.\"\"\"\r\n    p = (PROJECT_ROOT / rel_path).resolve()\r\n    if PROJECT_ROOT not in p.parents and p != PROJECT_ROOT:\r\n        raise ValueError(\"Chemin en dehors du projet interdit.\")\r\n    return p\r\n\r\ndef list_project_files(start: str = \"app\") -> List[str]:\r\n    base = safe_path(start)\r\n    out: List[str] = []\r\n    for p in base.rglob(\"*\"):\r\n        if p.is_file() and p.suffix.lower() in ALLOW_EXT:\r\n            out.append(str(p.relative_to(PROJECT_ROOT)))\r\n    return sorted(out)\r\n\r\ndef read_file(rel_path: str, max_bytes: int = 300_000) -> str:\r\n    p = safe_path(rel_path)\r\n    data = p.read_bytes()\r\n    if len(data) > max_bytes:\r\n        raise ValueErr",
      "meta": {
        "kind": "code",
        "file": "app\\services\\code_io.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "5ab56985c7bec3cac16f332e7271d8816b34de7cd2d3061af57a636e14854856"
      }
    },
    {
      "text": " str, max_bytes: int = 300_000) -> str:\r\n    p = safe_path(rel_path)\r\n    data = p.read_bytes()\r\n    if len(data) > max_bytes:\r\n        raise ValueError(\"Fichier trop volumineux pour l'aper√ßu.\")\r\n    return data.decode(\"utf-8\", errors=\"replace\")\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\code_io.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "6d8bc8d433788da696ff0b62bb7182acf110381f117fb6e7c9513e853dbc1783"
      }
    },
    {
      "text": "Ôªøimport requests, time, threading\r\nfrom urllib.parse import urlparse\r\nfrom urllib import robotparser\r\nfrom bs4 import BeautifulSoup\r\nimport trafilatura\r\n\r\nHEADERS = {\"User-Agent\": \"AssistantDylan/1.0 (+https://example.local) Contact:dylan@example.local\"}\r\nREQUEST_TIMEOUT = 8\r\nDEFAULT_DELAY_PER_DOMAIN = 1.0\r\n\r\n_robots_cache = {}\r\n_last_access = {}\r\n_lock = threading.Lock()\r\n\r\ndef extract_with_bs4(html: str, max_chars: int = 1600) -> str:\r\n    soup = BeautifulSoup(html, \"html.parser\")\r\n    for tag in soup([\"script\",\"style\",\"noscript\"]): tag.decompose()\r\n    text = \" \".join(soup.get_text(separator=\" \").split())\r\n    return text[:max_chars]\r\n\r\ndef get_domain(url: str) -> str:\r\n    try:\r\n        return urlparse(url).netloc.lower()\r\n    except Exception:\r\n        return \"\"\r\n\r\ndef can_fetch_url(url: str, user_agent: str = HEADERS[\"User-Agent\"]) -> bool:\r\n    dom = get_domain(url)\r\n    if not dom: return False\r\n    base = f\"{urlparse(url).scheme}://{dom}\"\r\n    rp = _robots_cache.get(base)\r\n   ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\extract.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "921a5548c510c26e4487d3034d9669311f01e144b50102745fb6acfcb7da5852"
      }
    },
    {
      "text": "-> bool:\r\n    dom = get_domain(url)\r\n    if not dom: return False\r\n    base = f\"{urlparse(url).scheme}://{dom}\"\r\n    rp = _robots_cache.get(base)\r\n    if rp is None:\r\n        rp = robotparser.RobotFileParser()\r\n        try:\r\n            rp.set_url(base + \"/robots.txt\"); rp.read()\r\n            _robots_cache[base] = rp\r\n        except Exception:\r\n            _robots_cache[base] = None\r\n            return True\r\n    if rp is None: return True\r\n    return rp.can_fetch(user_agent, url)\r\n\r\ndef polite_wait(domain: str, min_interval: float = DEFAULT_DELAY_PER_DOMAIN):\r\n    with _lock:\r\n        last = _last_access.get(domain)\r\n        now = time.time()\r\n        if last:\r\n            wait = min_interval - (now - last)\r\n            if wait > 0: time.sleep(wait)\r\n        _last_access[domain] = time.time()\r\n\r\ndef fetch_metadata(url: str) -> dict:\r\n    resp = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)\r\n    resp.raise_for_status()\r\n    html = resp.text\r\n    try:\r\n        txt = trafila",
      "meta": {
        "kind": "code",
        "file": "app\\services\\extract.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "e337d538afda56a5625528a2bb758c759036608e3fc7aa34ded773f7a4dca3db"
      }
    },
    {
      "text": "resp = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)\r\n    resp.raise_for_status()\r\n    html = resp.text\r\n    try:\r\n        txt = trafilatura.extract(html) or \"\"\r\n        extract = \" \".join(txt.split())[:500] if txt and len(txt.strip()) > 40 else \"\"\r\n    except Exception:\r\n        extract = \"\"\r\n    soup = BeautifulSoup(html, \"html.parser\")\r\n    title_tag = soup.find(\"title\")\r\n    title = title_tag.get_text(strip=True) if title_tag else None\r\n    meta = soup.find(\"meta\", attrs={\"name\":\"description\"}) or soup.find(\"meta\", attrs={\"property\":\"og:description\"})\r\n    snippet = meta.get(\"content\").strip() if meta and meta.get(\"content\") else None\r\n    if not snippet and not extract:\r\n        node = soup.find(\"p\")\r\n        if node and node.get_text(strip=True):\r\n            snippet = node.get_text(strip=True)[:300]\r\n    return {\"title\": title, \"snippet\": snippet, \"extract\": extract}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\extract.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "a14f319f64e3b628a910398d0a3ceb902a2c6650874e37ca2086969661a522e5"
      }
    },
    {
      "text": "e\": title, \"snippet\": snippet, \"extract\": extract}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\extract.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "91085127bd7090025fc326124607b1625276b7f104beecef23009b0845bf938c"
      }
    },
    {
      "text": "# app/services/memory.py\r\nimport os, json\r\nfrom typing import List, Dict, Any, Optional, Iterable, Tuple\r\nimport torch\r\nfrom sentence_transformers import SentenceTransformer, util\r\n\r\nDATA_DIR = \"data\"\r\nos.makedirs(DATA_DIR, exist_ok=True)\r\nKV_PATH = os.path.join(DATA_DIR, \"memory.json\")\r\n\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\r\n\r\ndef _load() -> Dict[str, Any]:\r\n    if not os.path.exists(KV_PATH):\r\n        return {\"items\": []}\r\n    with open(KV_PATH, \"r\", encoding=\"utf8\") as f:\r\n        return json.load(f)\r\n\r\ndef _save(d: Dict[str, Any]) -> None:\r\n    with open(KV_PATH, \"w\", encoding=\"utf8\") as f:\r\n        json.dump(d, f, ensure_ascii=False, indent=2)\r\n\r\ndef add_to_memory(text: str) -> None:\r\n    add_to_memory_item(text, meta=None)\r\n\r\ndef add_to_memory_item(text: str, meta: Optional[Dict[str, Any]]) -> None:\r\n    d = _load()\r\n    d[\"items\"].append({\"text\": text, \"meta\": meta or {}})\r\n    _save(d)\r\n\r\ndef ad",
      "meta": {
        "kind": "code",
        "file": "app\\services\\memory.py",
        "chunk": 0,
        "total_chunks": 5,
        "chunk_sha": "a71efb7c8de3e72fb5e891f52f3e8e329201d2f4b59f15a855896e1dfc92472f"
      }
    },
    {
      "text": "ext: str, meta: Optional[Dict[str, Any]]) -> None:\r\n    d = _load()\r\n    d[\"items\"].append({\"text\": text, \"meta\": meta or {}})\r\n    _save(d)\r\n\r\ndef add_many(items: Iterable[Dict[str, Any]]) -> int:\r\n    d = _load()\r\n    count = 0\r\n    for it in items:\r\n        txt = it.get(\"text\", \"\")\r\n        if not txt:\r\n            continue\r\n        d[\"items\"].append({\"text\": txt, \"meta\": it.get(\"meta\") or {}})\r\n        count += 1\r\n    _save(d)\r\n    return count\r\n\r\ndef remove_by_meta(match: Dict[str, Any]) -> int:\r\n    \"\"\"\r\n    Supprime tous les items dont la meta contient toutes les paires key=val de `match`.\r\n    Retourne le nombre supprim√©.\r\n    \"\"\"\r\n    d = _load()\r\n    old = d.get(\"items\", [])\r\n    def ok(m):\r\n        return all(m.get(k) == v for k, v in match.items())\r\n    new = [it for it in old if not ok(it.get(\"meta\", {}))]\r\n    removed = len(old) - len(new)\r\n    d[\"items\"] = new\r\n    _save(d)\r\n    return removed\r\n\r\ndef add_many_unique(items: Iterable[Dict[str, Any]], unique_keys: Tuple[str",
      "meta": {
        "kind": "code",
        "file": "app\\services\\memory.py",
        "chunk": 1,
        "total_chunks": 5,
        "chunk_sha": "03143f24fd228439f3755e933c3f11f0e1fc5f98b8d21f19f080187d02a8d9cb"
      }
    },
    {
      "text": "old) - len(new)\r\n    d[\"items\"] = new\r\n    _save(d)\r\n    return removed\r\n\r\ndef add_many_unique(items: Iterable[Dict[str, Any]], unique_keys: Tuple[str, ...] = (\"kind\",\"file\",\"chunk_sha\")) -> int:\r\n    \"\"\"\r\n    Ajoute en √©vitant les doublons bas√©s sur des cl√©s m√©ta (par d√©faut: kind,file,chunk_sha).\r\n    \"\"\"\r\n    d = _load()\r\n    existing = set()\r\n    for it in d.get(\"items\", []):\r\n        meta = it.get(\"meta\", {})\r\n        key = tuple(meta.get(k) for k in unique_keys)\r\n        existing.add(key)\r\n\r\n    added = 0\r\n    for it in items:\r\n        meta = it.get(\"meta\") or {}\r\n        key = tuple(meta.get(k) for k in unique_keys)\r\n        if key in existing:\r\n            continue\r\n        txt = it.get(\"text\", \"\")\r\n        if not txt:\r\n            continue\r\n        d[\"items\"].append({\"text\": txt, \"meta\": meta})\r\n        existing.add(key)\r\n        added += 1\r\n\r\n    _save(d)\r\n    return added\r\n\r\ndef search_memory(query: str, k: int = 5, filter_meta: Optional[Dict[str, Any]] = None) -> List[Dict[",
      "meta": {
        "kind": "code",
        "file": "app\\services\\memory.py",
        "chunk": 2,
        "total_chunks": 5,
        "chunk_sha": "bf61f24681fb057a4dc752d98ecd67b31993028823e882d6d1029a4db8422537"
      }
    },
    {
      "text": " added += 1\r\n\r\n    _save(d)\r\n    return added\r\n\r\ndef search_memory(query: str, k: int = 5, filter_meta: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:\r\n    d = _load()\r\n    corpus_items = d.get(\"items\", [])\r\n    if filter_meta:\r\n        def ok(m):\r\n            return all(m.get(k) == v for k, v in filter_meta.items())\r\n        corpus_items = [it for it in corpus_items if ok(it.get(\"meta\", {}))]\r\n    if not corpus_items:\r\n        return []\r\n\r\n    corpus = [it[\"text\"] for it in corpus_items]\r\n    qv = model.encode([query], convert_to_tensor=True, normalize_embeddings=True)\r\n    cv = model.encode(corpus, convert_to_tensor=True, normalize_embeddings=True)\r\n    sims = util.cos_sim(qv, cv)[0].tolist()\r\n\r\n    scored = []\r\n    for it, s in zip(corpus_items, sims):\r\n        scored.append({\"text\": it[\"text\"], \"meta\": it.get(\"meta\", {}), \"score\": float(s)})\r\n    scored.sort(key=lambda x: x[\"score\"], reverse=True)\r\n    return scored[:k]\r\n\r\ndef chunk_text(text: str, chunk: int = 1000, ove",
      "meta": {
        "kind": "code",
        "file": "app\\services\\memory.py",
        "chunk": 3,
        "total_chunks": 5,
        "chunk_sha": "13e31e157f21b13cf3eff5d16b18f1b167de400df8fc46773db159c1b5f736db"
      }
    },
    {
      "text": "score\": float(s)})\r\n    scored.sort(key=lambda x: x[\"score\"], reverse=True)\r\n    return scored[:k]\r\n\r\ndef chunk_text(text: str, chunk: int = 1000, overlap: int = 150) -> List[str]:\r\n    if chunk <= 0:\r\n        return [text]\r\n    out = []\r\n    n = len(text)\r\n    i = 0\r\n    step = chunk - overlap if chunk > overlap else chunk\r\n    while i < n:\r\n        out.append(text[i:i+chunk])\r\n        i += step\r\n    return out\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\memory.py",
        "chunk": 4,
        "total_chunks": 5,
        "chunk_sha": "270520218dc672034095b65bb051abbfbfc09aed84062aba0aed3034886fd0f6"
      }
    },
    {
      "text": "Ôªøfrom ..database import db\r\nfrom ..models import SearchResult\r\n\r\ndef load_prefs():\r\n    conn = db()\r\n    row = conn.execute(\"SELECT * FROM prefs WHERE id=1\").fetchone()\r\n    conn.close()\r\n    if not row:\r\n        return {}\r\n    def split_csv(s):\r\n        return [x.strip().lower() for x in (s or \"\").split(\",\") if x.strip()]\r\n    return {\r\n        \"preferred_domains\": set(split_csv(row[\"preferred_domains\"])),\r\n        \"blocked_domains\": set(split_csv(row[\"blocked_domains\"])),\r\n        \"preferred_keywords\": set(split_csv(row[\"preferred_keywords\"])),\r\n        \"blocked_keywords\": set(split_csv(row[\"blocked_keywords\"])),\r\n        \"like_weight\": float(row[\"like_weight\"]),\r\n        \"dislike_weight\": float(row[\"dislike_weight\"]),\r\n        \"domain_boost\": float(row[\"domain_boost\"]),\r\n        \"keyword_boost\": float(row[\"keyword_boost\"]),\r\n        \"strict_block\": bool(row[\"strict_block\"]) if \"strict_block\" in row.keys() else False,  # <--- AJOUT\r\n    }\r\n\r\ndef is_hard_block(domain: str, url: str, p",
      "meta": {
        "kind": "code",
        "file": "app\\services\\prefs.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "4d98f5ec11d555eab2b949d459fdd6c9d40cf08533a0ee41db0e0eb8c86a78c7"
      }
    },
    {
      "text": "trict_block\": bool(row[\"strict_block\"]) if \"strict_block\" in row.keys() else False,  # <--- AJOUT\r\n    }\r\n\r\ndef is_hard_block(domain: str, url: str, prefs: dict, fb_counts) -> bool:\r\n    \"\"\"Retourne True si on DOIT cacher le r√©sultat en mode strict.\"\"\"\r\n    if domain in (prefs.get(\"blocked_domains\") or set()):\r\n        return True\r\n    likes_domain, dislikes_domain, likes_url, dislikes_url = fb_counts\r\n    # si URL dislik√©e au moins 1x -> on bloque\r\n    if dislikes_url.get(url, 0) > 0:\r\n        return True\r\n    # si domaine massivement dislik√© -> on bloque aussi\r\n    if dislikes_domain.get(domain, 0) > 0:\r\n        return True\r\n    return False\r\n\r\n\r\ndef get_feedback_counts():\r\n    conn = db(); cur = conn.cursor()\r\n    likes_domain = {r[\"domain\"]: r[\"c\"] for r in cur.execute(\"SELECT domain, COUNT(*) c FROM feedback WHERE label='like' GROUP BY domain\")}\r\n    dislikes_domain = {r[\"domain\"]: r[\"c\"] for r in cur.execute(\"SELECT domain, COUNT(*) c FROM feedback WHERE label='dislike' GROUP BY ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\prefs.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "5032d3815b399baced2b9369138bd694c65b65bafcf4b6fbf4851f74398a0c83"
      }
    },
    {
      "text": "BY domain\")}\r\n    dislikes_domain = {r[\"domain\"]: r[\"c\"] for r in cur.execute(\"SELECT domain, COUNT(*) c FROM feedback WHERE label='dislike' GROUP BY domain\")}\r\n    likes_url = {r[\"url\"]: r[\"c\"] for r in cur.execute(\"SELECT url, COUNT(*) c FROM feedback WHERE label='like' GROUP BY url\")}\r\n    dislikes_url = {r[\"url\"]: r[\"c\"] for r in cur.execute(\"SELECT url, COUNT(*) c FROM feedback WHERE label='dislike' GROUP BY url\")}\r\n    conn.close()\r\n    return likes_domain, dislikes_domain, likes_url, dislikes_url\r\n\r\ndef score_result(item: SearchResult, query: str, prefs: dict, fb_counts, base_rank: int) -> float:\r\n    domain = (item.domain or \"\").lower()\r\n    title = (item.title or \"\")\r\n    snippet = (item.snippet or \"\")\r\n    text = f\"{title} {snippet}\".lower()\r\n    base = 1.0 / (base_rank + 1)\r\n    likes_domain, dislikes_domain, likes_url, dislikes_url = fb_counts\r\n    s_fb = 0.0\r\n    s_fb += likes_domain.get(domain, 0) * prefs[\"like_weight\"]\r\n    s_fb += dislikes_domain.get(domain, 0) * prefs[",
      "meta": {
        "kind": "code",
        "file": "app\\services\\prefs.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "d58050014a54737f3c02d399a0d73a2a804d5cea1427448c44ef98cdf3363c9d"
      }
    },
    {
      "text": "s_url = fb_counts\r\n    s_fb = 0.0\r\n    s_fb += likes_domain.get(domain, 0) * prefs[\"like_weight\"]\r\n    s_fb += dislikes_domain.get(domain, 0) * prefs[\"dislike_weight\"]\r\n    s_fb += likes_url.get(item.url, 0) * (prefs[\"like_weight\"] * 1.5)\r\n    s_fb += dislikes_url.get(item.url, 0) * (prefs[\"dislike_weight\"] * 1.5)\r\n    s_dom = 0.0\r\n    if domain in prefs[\"preferred_domains\"]: s_dom += prefs[\"domain_boost\"]\r\n    if domain in prefs[\"blocked_domains\"]:   s_dom -= prefs[\"domain_boost\"]\r\n    s_kw = 0.0\r\n    if any(k in text for k in prefs[\"preferred_keywords\"]): s_kw += prefs[\"keyword_boost\"]\r\n    if any(k in text for k in prefs[\"blocked_keywords\"]):   s_kw -= prefs[\"keyword_boost\"]\r\n    return base + s_fb + s_dom + s_kw\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\prefs.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "611bf321646c2bcec6925e327f5d4f59b595d04e068cc4d1380120d84f6f8229"
      }
    },
    {
      "text": "Ôªøimport os, json, time, threading\r\nfrom typing import List, Dict, Optional\r\nfrom urllib.parse import urlparse\r\nfrom urllib import robotparser\r\n\r\nimport requests\r\nimport trafilatura\r\nfrom bs4 import BeautifulSoup\r\n\r\n# Moteurs de recherche\r\ntry:\r\n    from ddgs import DDGS\r\nexcept Exception:\r\n    from duckduckgo_search import DDGS\r\nfrom googlesearch import search\r\n\r\n# Similarit√© / m√©moire (GPU si dispo)\r\nimport torch\r\nfrom sentence_transformers import SentenceTransformer, util\r\n\r\nHEADERS = {\"User-Agent\": \"AssistantDylan/1.0 (+https://example.local)\"}\r\nREQUEST_TIMEOUT = 8\r\nDEFAULT_MAX_RESULTS = 50\r\nDEFAULT_DELAY_PER_DOMAIN = 1.0\r\n\r\nDATA_DIR = \"data\"\r\nos.makedirs(DATA_DIR, exist_ok=True)\r\nDB_PATH = os.path.join(DATA_DIR, \"user_prefs.json\")\r\n\r\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nprint(f\"üß† Similarit√© sur {device.upper()}\")\r\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\r\n\r\n_lock = threading.Lock()\r\n_last_access: Dict[str, float] = {}\r\n_robots_cache: Dict[s",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 0,
        "total_chunks": 10,
        "chunk_sha": "af40155c1b9664374580f1815c84bebc554e7b73ac5731363f3bbdaebfafd23e"
      }
    },
    {
      "text": "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\r\n\r\n_lock = threading.Lock()\r\n_last_access: Dict[str, float] = {}\r\n_robots_cache: Dict[str, Optional[robotparser.RobotFileParser]] = {}\r\n\r\nclass SearchResult:\r\n    def __init__(self, title=None, url=None, snippet=None, extract=None, allowed_by_robots=None, domain=None, score=0.0):\r\n        self.title = title\r\n        self.url = url\r\n        self.snippet = snippet\r\n        self.extract = extract\r\n        self.allowed_by_robots = allowed_by_robots\r\n        self.domain = domain\r\n        self.score = score\r\n\r\n# ---------- JSON utils ----------\r\ndef load_json(path: str) -> dict:\r\n    if not os.path.exists(path):\r\n        return {\"preferences\": {\"boost\": [], \"ban\": []}, \"history\": []}\r\n    with open(path, \"r\", encoding=\"utf8\") as f:\r\n        return json.load(f)\r\n\r\ndef save_json(path: str, data: dict):\r\n    with open(path, \"w\", encoding=\"utf8\") as f:\r\n        json.dump(data, f, ensure_ascii=False, indent=2)\r\n\r\n# ---------- R√©seau /",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 1,
        "total_chunks": 10,
        "chunk_sha": "1c3f8e907cdbca89f6a17251837f33f59fbceb486a4c18c763f909f58a1f8f76"
      }
    },
    {
      "text": " str, data: dict):\r\n    with open(path, \"w\", encoding=\"utf8\") as f:\r\n        json.dump(data, f, ensure_ascii=False, indent=2)\r\n\r\n# ---------- R√©seau / parsing ----------\r\ndef get_domain(url: str) -> str:\r\n    try: return urlparse(url).netloc.lower()\r\n    except: return \"\"\r\n\r\ndef can_fetch_url(url: str) -> bool:\r\n    domain = get_domain(url)\r\n    if not domain: return False\r\n    base = f\"{urlparse(url).scheme}://{domain}\"\r\n    rp = _robots_cache.get(base)\r\n    if rp is None:\r\n        rp = robotparser.RobotFileParser()\r\n        try:\r\n            rp.set_url(base + \"/robots.txt\"); rp.read(); _robots_cache[base] = rp\r\n        except Exception:\r\n            _robots_cache[base] = None; return True\r\n    if rp is None: return True\r\n    return rp.can_fetch(HEADERS[\"User-Agent\"], url)\r\n\r\ndef polite_wait(domain: str, min_interval: float = DEFAULT_DELAY_PER_DOMAIN):\r\n    with _lock:\r\n        last = _last_access.get(domain); now = time.time()\r\n        if last:\r\n            wait = min_interval - (now",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 2,
        "total_chunks": 10,
        "chunk_sha": "33654316e79f3cc561ad195e43205b5bee2a6154e11fb652a5d0180db064d03d"
      }
    },
    {
      "text": "AY_PER_DOMAIN):\r\n    with _lock:\r\n        last = _last_access.get(domain); now = time.time()\r\n        if last:\r\n            wait = min_interval - (now - last)\r\n            if wait > 0: time.sleep(wait)\r\n        _last_access[domain] = time.time()\r\n\r\ndef fetch_page_text(url: str, timeout: int = 8, max_chars: int = 1600) -> str:\r\n    try:\r\n        downloaded = trafilatura.fetch_url(url, timeout=timeout)\r\n        if downloaded:\r\n            txt = trafilatura.extract(downloaded) or \"\"\r\n            if txt.strip(): return txt.strip()[:max_chars]\r\n    except Exception: pass\r\n    try:\r\n        resp = requests.get(url, headers=HEADERS, timeout=timeout)\r\n        if resp.ok and resp.text:\r\n            txt = trafilatura.extract(resp.text) or \"\"\r\n            if txt.strip(): return txt.strip()[:max_chars]\r\n            soup = BeautifulSoup(resp.text, \"html.parser\")\r\n            for t in soup([\"script\",\"style\",\"noscript\"]): t.decompose()\r\n            return \" \".join(soup.get_text(separator=\" \").split()",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 3,
        "total_chunks": 10,
        "chunk_sha": "057134f9604c1ff247b05291134b91836d413f76874fd3be163c509aa5a3a088"
      }
    },
    {
      "text": "ml.parser\")\r\n            for t in soup([\"script\",\"style\",\"noscript\"]): t.decompose()\r\n            return \" \".join(soup.get_text(separator=\" \").split())[:max_chars]\r\n    except Exception: pass\r\n    return \"\"\r\n\r\n# ---------- Moteurs ----------\r\ndef google_search_raw(query: str, max_results: int = 30):\r\n    try:\r\n        urls = list(search(query, num_results=max_results, lang=\"fr\"))\r\n        return [{\"title\": None, \"href\": u, \"body\": \"\"} for u in urls]\r\n    except Exception as e:\r\n        print(f\"[google] ‚ö†Ô∏è {e}\")\r\n        return []\r\n\r\ndef ddg_search_raw(query: str, max_results: int = 30):\r\n    try:\r\n        with DDGS() as ddgs:\r\n            return list(ddgs.text(query, region=\"fr-fr\", safesearch=\"moderate\", max_results=max_results))\r\n    except Exception as e:\r\n        print(f\"[ddg] ‚ö†Ô∏è {e}\")\r\n        return []\r\n\r\ndef hybrid_search(query: str, max_results: int = 30):\r\n    g = google_search_raw(query, max_results=max_results//2)\r\n    d = ddg_search_raw(query, max_results=max_results//2)\r\n ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 4,
        "total_chunks": 10,
        "chunk_sha": "039a577fd23d53507451a912a77d0c1ec2df32c7bde17a1db10cbf32c4f85b73"
      }
    },
    {
      "text": "r, max_results: int = 30):\r\n    g = google_search_raw(query, max_results=max_results//2)\r\n    d = ddg_search_raw(query, max_results=max_results//2)\r\n    seen, out = set(), []\r\n    for r in g + d:\r\n        url = r.get(\"href\") or r.get(\"url\")\r\n        if url and url not in seen:\r\n            seen.add(url); out.append(r)\r\n    return out\r\n\r\n# ---------- Feedback / pr√©f√©rences ----------\r\ndef record_feedback(url: str, liked: bool):\r\n    data = load_json(DB_PATH)\r\n    prefs = data.setdefault(\"preferences\", {\"boost\": [], \"ban\": []})\r\n    dom = get_domain(url)\r\n    if liked:\r\n        if dom not in prefs[\"boost\"]: prefs[\"boost\"].append(dom)\r\n    else:\r\n        if dom not in prefs[\"ban\"]: prefs[\"ban\"].append(dom)\r\n    save_json(DB_PATH, data)\r\n\r\ndef apply_preferences(results: List[SearchResult]) -> List[SearchResult]:\r\n    data = load_json(DB_PATH)\r\n    boost = set(data.get(\"preferences\", {}).get(\"boost\", []))\r\n    ban = set(data.get(\"preferences\", {}).get(\"ban\", []))\r\n    out = []\r\n    for it i",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 5,
        "total_chunks": 10,
        "chunk_sha": "7dab9dba0ffcd96df3db17f6786e3981ae223c33bd5dbad892bebb5fee4845ed"
      }
    },
    {
      "text": "\r\n    boost = set(data.get(\"preferences\", {}).get(\"boost\", []))\r\n    ban = set(data.get(\"preferences\", {}).get(\"ban\", []))\r\n    out = []\r\n    for it in results:\r\n        d = it.domain or \"\"\r\n        if any(b in d for b in ban):  # filtre dur\r\n            continue\r\n        if any(b in d for b in boost):\r\n            it.score += 2.0\r\n        out.append(it)\r\n    return out\r\n\r\n# ---------- Similarit√© : filtrer ce qui ressemble aux dislikes ----------\r\ndef filter_by_similarity(results: List[SearchResult]) -> List[SearchResult]:\r\n    data = load_json(DB_PATH)\r\n    dislikes = [ (h.get(\"title\",\"\") + \" \" + h.get(\"snippet\",\"\")).strip()\r\n                 for h in data.get(\"history\", []) if h.get(\"liked\") is False ]\r\n    dislikes = [t for t in dislikes if t]\r\n    if not dislikes:\r\n        return results\r\n    # Embeddings GPU/CPU\r\n    dislike_vecs = model.encode(dislikes, convert_to_tensor=True)  # [N, D]\r\n    kept = []\r\n    for it in results:\r\n        text = ((it.title or \"\") + \" \" + (it.snippet o",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 6,
        "total_chunks": 10,
        "chunk_sha": "4fc18952a20fea27de35fdb107bfa6fab7982b7c912c91c5e675b6042a15b433"
      }
    },
    {
      "text": "odel.encode(dislikes, convert_to_tensor=True)  # [N, D]\r\n    kept = []\r\n    for it in results:\r\n        text = ((it.title or \"\") + \" \" + (it.snippet or \"\")).strip()\r\n        if not text:\r\n            kept.append(it); continue\r\n        v = model.encode([text], convert_to_tensor=True)  # [1, D]\r\n        sim = float(util.max_sim(v1=v, v2=dislike_vecs))\r\n        if sim < 0.7:  # seuil de similarit√©\r\n            kept.append(it)\r\n    return kept\r\n\r\n# ---------- Rerank g√©n√©ral ----------\r\ndef rerank(results: List[SearchResult], query: str) -> List[SearchResult]:\r\n    results = apply_preferences(results)\r\n    results = filter_by_similarity(results)\r\n    # tri par score d√©croissant\r\n    results.sort(key=lambda x: x.score, reverse=True)\r\n    # Historique (best effort)\r\n    try:\r\n        data = load_json(DB_PATH)\r\n        for it in results[:30]:\r\n            data[\"history\"].append({\r\n                \"query\": query,\r\n                \"title\": it.title,\r\n                \"snippet\": it.snippet,\r\n     ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 7,
        "total_chunks": 10,
        "chunk_sha": "1e4c36b4d22ec094b99b4c448701618b0351facab9aaf0e377a73066b30df474"
      }
    },
    {
      "text": "          data[\"history\"].append({\r\n                \"query\": query,\r\n                \"title\": it.title,\r\n                \"snippet\": it.snippet,\r\n                \"url\": it.url,\r\n                \"domain\": it.domain,\r\n                \"liked\": None,  # sera rempli si tu cliques üëç/üëé\r\n                \"ts\": time.time()\r\n            })\r\n        save_json(DB_PATH, data)\r\n    except Exception:\r\n        pass\r\n    return results\r\n\r\n# ---------- Build enrichi ----------\r\ndef follow_and_build(raw: List[Dict], follow=False, max_per_domain=5, delay_per_domain=1.0) -> List[SearchResult]:\r\n    out: List[SearchResult] = []\r\n    counts: Dict[str, int] = {}\r\n    for r in raw:\r\n        url = r.get(\"href\") or r.get(\"url\")\r\n        if not url: continue\r\n        dom = get_domain(url)\r\n        ok = can_fetch_url(url)\r\n        it = SearchResult(\r\n            title=r.get(\"title\") or url,\r\n            url=url,\r\n            snippet=(r.get(\"body\") or \"\")[:300],\r\n            extract=None,\r\n            allowed_by_robo",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 8,
        "total_chunks": 10,
        "chunk_sha": "bc64aa925a36c837674605835d3f6043a2280bb92434cefa56232debfa10092f"
      }
    },
    {
      "text": "r.get(\"title\") or url,\r\n            url=url,\r\n            snippet=(r.get(\"body\") or \"\")[:300],\r\n            extract=None,\r\n            allowed_by_robots=ok,\r\n            domain=dom,\r\n            score=0.0\r\n        )\r\n        if follow and ok:\r\n            if counts.get(dom, 0) < max_per_domain:\r\n                polite_wait(dom, delay_per_domain)\r\n                it.extract = fetch_page_text(url)\r\n                counts[dom] = counts.get(dom, 0) + 1\r\n        out.append(it)\r\n        if len(out) >= DEFAULT_MAX_RESULTS: break\r\n    return out\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\search.py",
        "chunk": 9,
        "total_chunks": 10,
        "chunk_sha": "b22b15cf617678051a8a5a8e660d8e7f3a0c696e94de46e25214e0c0525a350a"
      }
    },
    {
      "text": "import os\r\nfrom app.services.chat_engine import llm_local\r\n\r\nNOTES_PATH = \"data/self_notes.txt\"\r\nos.makedirs(\"data\", exist_ok=True)\r\nif not os.path.exists(NOTES_PATH):\r\n    with open(NOTES_PATH, \"w\", encoding=\"utf8\") as f:\r\n        f.write(\"\")\r\n\r\nTEMPLATE = \"\"\"\r\nTu es AssistantDylan. Propose un patch de code clair et complet (un seul fichier),\r\npour am√©liorer l'assistant selon l'objectif: \"{objective}\"\r\n\r\nContraintes:\r\n- Retourne UNIQUEMENT le code final pr√™t √† coller (pas d'explication).\r\n- Utilise Python FastAPI si n√©cessaire.\r\n- Respecte l'architecture existante (app/services/*.py, app/routers/*.py).\r\n\"\"\"\r\n\r\ndef propose_code_improvement(objective: str) -> str:\r\n    prompt = TEMPLATE.format(objective=objective.strip())\r\n    return llm_local(prompt)\r\n\r\ndef add_note(text: str):\r\n    with open(NOTES_PATH, \"a\", encoding=\"utf8\") as f:\r\n        f.write(text.strip() + \"\\n\")\r\n\r\ndef list_notes():\r\n    with open(NOTES_PATH, \"r\", encoding=\"utf8\") as f:\r\n        return [l.strip() for l in f.read",
      "meta": {
        "kind": "code",
        "file": "app\\services\\self_update.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "cd34d90185e0ee491e6ce3749a24ad4d83a62beb8fbd639ad2c26cdc873a5356"
      }
    },
    {
      "text": "   f.write(text.strip() + \"\\n\")\r\n\r\ndef list_notes():\r\n    with open(NOTES_PATH, \"r\", encoding=\"utf8\") as f:\r\n        return [l.strip() for l in f.readlines() if l.strip()]\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\self_update.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "070553b1d49aa0ee7047bd68c3bb63ec97c76a28ff8a12bbb7c8c043b3f4afdf"
      }
    },
    {
      "text": "# app/services/startup_indexer.py\r\nfrom pathlib import Path\r\nimport os, json, hashlib\r\nfrom typing import Dict, Any, List\r\nfrom app.services.code_io import list_project_files, read_file, safe_path\r\nfrom app.services.memory import chunk_text, remove_by_meta, add_many_unique\r\n\r\nDATA_DIR = Path(\"data\")\r\nMANIFEST_PATH = DATA_DIR / \"code_manifest.json\"\r\n\r\ndef _ensure_data_dir():\r\n    DATA_DIR.mkdir(parents=True, exist_ok=True)\r\n\r\ndef _load_manifest() -> Dict[str, Any]:\r\n    _ensure_data_dir()\r\n    if not MANIFEST_PATH.exists():\r\n        return {\"version\": 1, \"files\": {}}\r\n    with MANIFEST_PATH.open(\"r\", encoding=\"utf8\") as f:\r\n        return json.load(f)\r\n\r\ndef _save_manifest(m: Dict[str, Any]):\r\n    _ensure_data_dir()\r\n    with MANIFEST_PATH.open(\"w\", encoding=\"utf8\") as f:\r\n        json.dump(m, f, ensure_ascii=False, indent=2)\r\n\r\ndef _sha256_text(s: str) -> str:\r\n    return hashlib.sha256(s.encode(\"utf-8\", errors=\"replace\")).hexdigest()\r\n\r\ndef startup_ingest_if_changed(\r\n    start: str =",
      "meta": {
        "kind": "code",
        "file": "app\\services\\startup_indexer.py",
        "chunk": 0,
        "total_chunks": 5,
        "chunk_sha": "a83a6f1c09ad6c921b29ad6ea8a038a9a5a14a72a3dfb91d41585357250984a9"
      }
    },
    {
      "text": "6_text(s: str) -> str:\r\n    return hashlib.sha256(s.encode(\"utf-8\", errors=\"replace\")).hexdigest()\r\n\r\ndef startup_ingest_if_changed(\r\n    start: str = \"app\",\r\n    allow_ext = (\".py\",\".js\",\".ts\",\".html\",\".css\",\".json\",\".md\",\".txt\"),\r\n    chunk: int = 1000,\r\n    overlap: int = 150,\r\n    max_bytes: int = 300_000,\r\n    verbose: bool = True\r\n):\r\n    \"\"\"\r\n    Au d√©marrage : scanne les fichiers, ne (r√©-)indexe que ceux qui ont chang√©.\r\n    √âcrit/maintient un manifeste data/code_manifest.json.\r\n    \"\"\"\r\n    try:\r\n        files = list_project_files(start)\r\n    except Exception as e:\r\n        if verbose:\r\n            print(f\"[startup_indexer] ‚ùå list_project_files error: {e}\")\r\n        return {\"ok\": False, \"error\": str(e)}\r\n\r\n    manifest = _load_manifest()\r\n    files_map: Dict[str, Any] = manifest.get(\"files\", {})\r\n\r\n    reindexed_files = 0\r\n    indexed_chunks = 0\r\n\r\n    for rel in files:\r\n        p = safe_path(rel)\r\n        if p.suffix.lower() not in allow_ext:\r\n            continue\r\n        tr",
      "meta": {
        "kind": "code",
        "file": "app\\services\\startup_indexer.py",
        "chunk": 1,
        "total_chunks": 5,
        "chunk_sha": "d631344d63db2b114f7811c26ad6e1134045aadc4ed8fa348cba0d51bdc579ee"
      }
    },
    {
      "text": "dexed_chunks = 0\r\n\r\n    for rel in files:\r\n        p = safe_path(rel)\r\n        if p.suffix.lower() not in allow_ext:\r\n            continue\r\n        try:\r\n            content = read_file(rel, max_bytes=max_bytes)\r\n        except Exception:\r\n            continue\r\n\r\n        sha = _sha256_text(content)\r\n        prev = files_map.get(rel)\r\n        if prev and prev.get(\"sha\") == sha:\r\n            # inchang√© ‚Üí skip\r\n            continue\r\n\r\n        # fichier chang√© ‚Üí re-chunk, purge ancienne m√©moire pour ce fichier, puis add unique\r\n        chunks = chunk_text(content, chunk=chunk, overlap=overlap)\r\n        # purge\r\n        removed = remove_by_meta({\"kind\":\"code\", \"file\": rel})\r\n        if verbose:\r\n            print(f\"[startup_indexer] üîÑ {rel} modifi√© (purge {removed} items)\")\r\n\r\n        items = []\r\n        for i, part in enumerate(chunks):\r\n            chunk_sha = _sha256_text(part)\r\n            items.append({\r\n                \"text\": part,\r\n                \"meta\": {\r\n                    \"kin",
      "meta": {
        "kind": "code",
        "file": "app\\services\\startup_indexer.py",
        "chunk": 2,
        "total_chunks": 5,
        "chunk_sha": "85ca0864994f761461c98bb8d7734e3206b3aa7c8f18548c136d95435eee5446"
      }
    },
    {
      "text": "        chunk_sha = _sha256_text(part)\r\n            items.append({\r\n                \"text\": part,\r\n                \"meta\": {\r\n                    \"kind\": \"code\",\r\n                    \"file\": rel,\r\n                    \"chunk\": i,\r\n                    \"total_chunks\": len(chunks),\r\n                    \"chunk_sha\": chunk_sha\r\n                }\r\n            })\r\n        added = add_many_unique(items, unique_keys=(\"kind\",\"file\",\"chunk_sha\"))\r\n        files_map[rel] = {\r\n            \"sha\": sha,\r\n            \"chunks\": [{\"idx\": i, \"sha\": it[\"meta\"][\"chunk_sha\"]} for i, it in enumerate(items)]\r\n        }\r\n        reindexed_files += 1\r\n        indexed_chunks += added\r\n\r\n    manifest[\"files\"] = files_map\r\n    _save_manifest(manifest)\r\n\r\n    if verbose:\r\n        print(f\"[startup_indexer] ‚úÖ reindexed_files={reindexed_files} indexed_chunks={indexed_chunks}\")\r\n    return {\"ok\": True, \"reindexed_files\": reindexed_files, \"indexed_chunks\": indexed_chunks}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\startup_indexer.py",
        "chunk": 3,
        "total_chunks": 5,
        "chunk_sha": "9438a369bb85bf90416a387a288f784178f2ae3260df1ab3f3fd5863e5c017fb"
      }
    },
    {
      "text": "s}\")\r\n    return {\"ok\": True, \"reindexed_files\": reindexed_files, \"indexed_chunks\": indexed_chunks}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\startup_indexer.py",
        "chunk": 4,
        "total_chunks": 5,
        "chunk_sha": "f455c09b819fc7c8cacab9a401db03664d08d0756318d59c1f65bbb137788d9c"
      }
    },
    {
      "text": "# app/services/trace_logger.py\r\nfrom pathlib import Path\r\nfrom datetime import datetime\r\nimport json\r\nfrom typing import Optional, Dict, Any, List\r\n\r\nLOG_DIR = Path(\"data/logs\")\r\nLOG_FILE = LOG_DIR / \"generated_code_traces.jsonl\"\r\n\r\ndef _ensure_dirs():\r\n    try:\r\n        LOG_DIR.mkdir(parents=True, exist_ok=True)\r\n    except Exception as e:\r\n        raise RuntimeError(f\"Impossible de cr√©er {LOG_DIR}: {e}\")\r\n\r\ndef write_code_trace(code: str, source: str = \"self_review\", meta: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\r\n    \"\"\"\r\n    √âcrit imm√©diatement (synchrone) une ligne JSON dans generated_code_traces.jsonl.\r\n    Retourne le chemin du fichier pour v√©rification.\r\n    \"\"\"\r\n    _ensure_dirs()\r\n    rec = {\r\n        \"ts\": datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\",\r\n        \"source\": source,\r\n        \"meta\": meta or {},\r\n        \"code\": code,\r\n    }\r\n    line = json.dumps(rec, ensure_ascii=False)\r\n    with LOG_FILE.open(\"a\", encoding=\"utf-8\") as f:\r\n        f.write(lin",
      "meta": {
        "kind": "code",
        "file": "app\\services\\trace_logger.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "b2b7a974aedd2c9b63cf216ab8fc7b6cd13ccdf563448153427426ce78034135"
      }
    },
    {
      "text": "        \"code\": code,\r\n    }\r\n    line = json.dumps(rec, ensure_ascii=False)\r\n    with LOG_FILE.open(\"a\", encoding=\"utf-8\") as f:\r\n        f.write(line + \"\\n\")\r\n    return {\"ok\": True, \"path\": str(LOG_FILE), \"bytes\": len(line)}\r\n\r\ndef read_traces(limit: int = 100) -> List[Dict[str, Any]]:\r\n    _ensure_dirs()\r\n    if not LOG_FILE.exists():\r\n        return []\r\n    out: List[Dict[str, Any]] = []\r\n    with LOG_FILE.open(\"r\", encoding=\"utf-8\") as f:\r\n        for line in f:\r\n            line = line.strip()\r\n            if not line:\r\n                continue\r\n            try:\r\n                out.append(json.loads(line))\r\n            except Exception:\r\n                continue\r\n    return out[-limit:]\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\trace_logger.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "3a3d6d320ab6daa882dbe6e5b337c8bebbfcc817dfdd5b7155f9bc46db558b2e"
      }
    },
    {
      "text": "Ôªø<!doctype html>\r\n<html lang=\"fr\">\r\n<head>\r\n  <meta charset=\"utf-8\" />\r\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n  <title>Assistant de Dylan ‚Äî Deep Search</title>\r\n  <script src=\"https://cdn.tailwindcss.com\"></script>\r\n  <style>\r\n    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, \"Liberation Mono\", monospace; }\r\n    .card { border-radius: 1rem; box-shadow: 0 6px 24px rgba(0,0,0,.08); }\r\n  </style>\r\n</head>\r\n<body class=\"bg-gray-50 text-gray-900\">\r\n  <div class=\"max-w-5xl mx-auto p-6\">\r\n    <h1 class=\"text-2xl font-semibold mb-4\">üîé Assistant de Dylan ‚Äî Deep Search</h1>\r\n\r\n    <div class=\"card bg-white p-4 mb-6\">\r\n      <div class=\"grid grid-cols-1 md:grid-cols-6 gap-3 items-end\">\r\n        <div class=\"md:col-span-3\">\r\n          <label class=\"block text-sm mb-1\">Requ√™te</label>\r\n          <input id=\"q\" type=\"text\" placeholder=\"ex: tendances IA en entreprise 2025\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 0,
        "total_chunks": 9,
        "chunk_sha": "f7b3cd9eb80bf52c0a93ccad07134e4a706f5fe6fecc7f654e5a9d17ce1cabd2"
      }
    },
    {
      "text": "         <input id=\"q\" type=\"text\" placeholder=\"ex: tendances IA en entreprise 2025\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Max r√©sultats</label>\r\n          <input id=\"max_results\" type=\"number\" min=\"1\" max=\"200\" value=\"30\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Max/domain</label>\r\n          <input id=\"max_per_domain\" type=\"number\" min=\"1\" max=\"50\" value=\"3\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div>\r\n          <label class=\"block text-sm mb-1\">Delay/domain (s)</label>\r\n          <input id=\"delay_per_domain\" type=\"number\" step=\"0.1\" min=\"0\" max=\"10\" value=\"1.2\"\r\n                 clas",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 1,
        "total_chunks": 9,
        "chunk_sha": "e853119bf5f4704a6fb28a83a3b89e40874a659f1d7b15fb92e284e5f785425e"
      }
    },
    {
      "text": "sm mb-1\">Delay/domain (s)</label>\r\n          <input id=\"delay_per_domain\" type=\"number\" step=\"0.1\" min=\"0\" max=\"10\" value=\"1.2\"\r\n                 class=\"w-full rounded-lg border px-3 py-2 focus:outline-none focus:ring focus:ring-indigo-200\" />\r\n        </div>\r\n        <div class=\"flex items-center gap-3\">\r\n          <label class=\"inline-flex items-center gap-2\">\r\n            <input id=\"follow\" type=\"checkbox\" class=\"h-4 w-4\" />\r\n            <span>Suivre liens</span>\r\n          </label>\r\n          <label class=\"inline-flex items-center gap-2\">\r\n            <input id=\"pretty\" type=\"checkbox\" class=\"h-4 w-4\" />\r\n            <span>JSON joli</span>\r\n          </label>\r\n        </div>\r\n        <div class=\"md:col-span-6 flex gap-3\">\r\n          <button id=\"go\" class=\"rounded-lg bg-indigo-600 text-white px-4 py-2 hover:bg-indigo-700\">Rechercher</button>\r\n          <button id=\"clear\" class=\"rounded-lg bg-gray-200 text-gray-800 px-4 py-2 hover:bg-gray-300\">Effacer</button>\r\n        </div>\r\n      ",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 2,
        "total_chunks": 9,
        "chunk_sha": "ad34f4650fdf9c1c0aedd7997ebee0aed877199118218d857140f7ed9fd99d27"
      }
    },
    {
      "text": "utton>\r\n          <button id=\"clear\" class=\"rounded-lg bg-gray-200 text-gray-800 px-4 py-2 hover:bg-gray-300\">Effacer</button>\r\n        </div>\r\n      </div>\r\n    </div>\r\n\r\n    <div id=\"status\" class=\"text-sm text-gray-600 mb-3\"></div>\r\n    <div id=\"results\" class=\"space-y-4\"></div>\r\n\r\n    <details class=\"mt-8\">\r\n      <summary class=\"cursor-pointer text-sm text-gray-600\">Voir la r√©ponse JSON brute</summary>\r\n      <pre id=\"raw\" class=\"mono text-xs bg-white p-4 rounded-lg overflow-auto mt-2\"></pre>\r\n    </details>\r\n  </div>\r\n\r\n<script>\r\nconst $ = (sel) => document.querySelector(sel);\r\nconst esc = (s) => (s || \"\").toString().replace(/[&<>]/g, c => ({'&':'&amp;','<':'&lt;','>':'&gt;'}[c]) );\r\n\r\nasync function run() {\r\n  const q = $(\"#q\").value.trim();\r\n  if (!q) { $(\"#status\").textContent = \"Saisis une requ√™te.\"; return; }\r\n\r\n  const max_results = +$(\"#max_results\").value || 30;\r\n  const follow = $(\"#follow\").checked;\r\n  const max_per_domain = +$(\"#max_per_domain\").value || 3;\r\n  const de",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 3,
        "total_chunks": 9,
        "chunk_sha": "9ebf8ae2aaeeda6cc0a832c3b1710bc20df1677e6315cb6920d29d32de3234fd"
      }
    },
    {
      "text": "ults = +$(\"#max_results\").value || 30;\r\n  const follow = $(\"#follow\").checked;\r\n  const max_per_domain = +$(\"#max_per_domain\").value || 3;\r\n  const delay_per_domain = +$(\"#delay_per_domain\").value || 1.2;\r\n  const pretty = $(\"#pretty\").checked;\r\n\r\n  const params = new URLSearchParams({ q, max_results, follow, max_per_domain, delay_per_domain, pretty, personalize: true });\r\n  const url = `/deep_search?${params.toString()}`;\r\n\r\n  $(\"#status\").textContent = \"Recherche en cours‚Ä¶\";\r\n  $(\"#results\").innerHTML = \"\";\r\n  $(\"#raw\").textContent = \"\";\r\n\r\n  try {\r\n    const res = await fetch(url);\r\n    const txt = await res.text();\r\n    let data;\r\n    try { data = JSON.parse(txt); } catch { data = null; }\r\n    if (data && data.results) {\r\n      renderCards(data);\r\n      $(\"#raw\").textContent = JSON.stringify(data, null, 2);\r\n      $(\"#status\").textContent = `OK ‚Äî ${data.results.length} r√©sultats (follow=${data.meta.follow_performed ? \"oui\" : \"non\"})`;\r\n    } else {\r\n      $(\"#raw\").textContent = tx",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 4,
        "total_chunks": 9,
        "chunk_sha": "2d26e20dd9eb480446350ed88652a6de100c0879c64ca82c7e0d92408fc52108"
      }
    },
    {
      "text": "tent = `OK ‚Äî ${data.results.length} r√©sultats (follow=${data.meta.follow_performed ? \"oui\" : \"non\"})`;\r\n    } else {\r\n      $(\"#raw\").textContent = txt;\r\n      $(\"#status\").textContent = \"R√©ponse format√©e (pretty)\";\r\n    }\r\n  } catch (e) {\r\n    $(\"#status\").textContent = \"Erreur: \" + e.message;\r\n  }\r\n}\r\n\r\nasync function sendFeedback(item, label) {\r\n  try {\r\n    await fetch(\"/feedback\", {\r\n      method: \"POST\",\r\n      headers: {\"Content-Type\": \"application/json\"},\r\n      body: JSON.stringify({ url: item.url, domain: item.domain, title: item.title, label })\r\n    });\r\n  } catch (e) { console.warn(\"feedback error\", e); }\r\n}\r\n\r\nfunction renderCards(data) {\r\n  const wrap = $(\"#results\"); wrap.innerHTML = \"\";\r\n  for (const it of data.results) {\r\n    const allowed = it.allowed_by_robots === false\r\n      ? '<span class=\"text-xs bg-red-100 text-red-700 px-2 py-1 rounded-full\">robots.txt: non</span>'\r\n      : '<span class=\"text-xs bg-green-100 text-green-700 px-2 py-1 rounded-full\">robots.txt: ok",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 5,
        "total_chunks": 9,
        "chunk_sha": "681206a0efa07aca67cd44a01833d76d943824b424d482213a550ec3e67a1743"
      }
    },
    {
      "text": "-700 px-2 py-1 rounded-full\">robots.txt: non</span>'\r\n      : '<span class=\"text-xs bg-green-100 text-green-700 px-2 py-1 rounded-full\">robots.txt: ok</span>';\r\n\r\n    const card = document.createElement(\"div\");\r\n    card.className = \"card bg-white p-4\";\r\n    card.innerHTML = `\r\n      <div class=\"flex flex-wrap items-center gap-2 mb-2\">\r\n        <a class=\"text-lg font-medium text-indigo-700 hover:underline\" href=\"${esc(it.url)}\" target=\"_blank\" rel=\"noopener\">\r\n          ${esc(it.title || it.url)}\r\n        </a>\r\n        <span class=\"text-xs bg-gray-100 text-gray-700 px-2 py-1 rounded-full\">${esc(it.domain || \"\")}</span>\r\n        ${allowed}\r\n      </div>\r\n      ${it.snippet ? `<p class=\"text-sm text-gray-700 mb-2\">${esc(it.snippet)}</p>` : ``}\r\n      ${it.extract ? `<details class=\"mt-1\"><summary class=\"text-sm text-gray-600 cursor-pointer\">Extrait</summary><p class=\"text-sm text-gray-800 mt-1\">${esc(it.extract)}</p></details>` : ``}\r\n      <div class=\"mt-2 flex gap-2\">\r\n        <button ",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 6,
        "total_chunks": 9,
        "chunk_sha": "b24dc9b29acfcff254b018b5e6888f86374701b0e2da305d82e163bc4b048d30"
      }
    },
    {
      "text": ">Extrait</summary><p class=\"text-sm text-gray-800 mt-1\">${esc(it.extract)}</p></details>` : ``}\r\n      <div class=\"mt-2 flex gap-2\">\r\n        <button class=\"px-3 py-1 rounded bg-green-100 text-green-800 hover:bg-green-200 text-sm\" data-act=\"like\">üëç Utile</button>\r\n        <button class=\"px-3 py-1 rounded bg-red-100 text-red-800 hover:bg-red-200 text-sm\" data-act=\"dislike\">üëé Sans int√©r√™t</button>\r\n      </div>\r\n      <div class=\"mt-2 text-xs text-gray-500 mono\">${esc(it.url)}</div>\r\n    `;\r\n    card.querySelector('[data-act=\"like\"]').addEventListener(\"click\", async () => { await sendFeedback(it, \"like\"); card.style.outline = \"2px solid #16a34a55\"; });\r\n    card.querySelector('[data-act=\"dislike\"]').addEventListener(\"click\", async () => { await sendFeedback(it, \"dislike\"); card.style.outline = \"2px solid #dc262655\"; });\r\n    wrap.appendChild(card);\r\n  }\r\n}\r\n\r\ndocument.addEventListener(\"DOMContentLoaded\", () => {\r\n  $(\"#go\").addEventListener(\"click\", run);\r\n  $(\"#clear\").addEventListener(",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 7,
        "total_chunks": 9,
        "chunk_sha": "5c6199c32d39312780118ec9ae5c98cd235d255bb2569a9b708095e51b8ee6c6"
      }
    },
    {
      "text": "d(card);\r\n  }\r\n}\r\n\r\ndocument.addEventListener(\"DOMContentLoaded\", () => {\r\n  $(\"#go\").addEventListener(\"click\", run);\r\n  $(\"#clear\").addEventListener(\"click\", () => { $(\"#q\").value = \"\"; $(\"#results\").innerHTML = \"\"; $(\"#raw\").textContent = \"\"; $(\"#status\").textContent = \"\"; });\r\n  $(\"#q\").addEventListener(\"keydown\", (e) => { if (e.key === \"Enter\") run(); });\r\n});\r\n</script>\r\n</body>\r\n</html>\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\static\\ui.html",
        "chunk": 8,
        "total_chunks": 9,
        "chunk_sha": "7f3fb3f77f102c679052c375292bbeb70029210bb0dfd2318de8879598dd630d"
      }
    },
    {
      "text": "# app/routers/verify.py\r\nfrom fastapi import APIRouter, HTTPException, Query\r\nfrom pydantic import BaseModel, Field\r\nfrom typing import Optional, Dict, Any\r\nfrom app.services.verification import verify_improvement, verify_file_patch\r\nfrom app.services.code_io import read_file\r\n\r\nrouter = APIRouter(tags=[\"verification\"])\r\n\r\nclass VerifyIn(BaseModel):\r\n    objective: str = Field(..., min_length=5)\r\n    context: str = Field(..., description=\"Contexte/code existant (extrait pertinent)\")\r\n    proposal: str = Field(..., description=\"Patch ou code propos√© pour l'am√©lioration\")\r\n\r\n@router.post(\"/verify/improvement\")\r\ndef verify_endpoint(inp: VerifyIn):\r\n    try:\r\n        result = verify_improvement(inp.objective, inp.context, inp.proposal)\r\n        return {\"ok\": True, \"result\": result}\r\n    except Exception as e:\r\n        raise HTTPException(500, str(e))\r\n\r\n@router.post(\"/verify/file_patch\")\r\ndef verify_file_patch_endpoint(\r\n    objective: str = Query(..., min_length=5),\r\n    file_path: str = ",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\verify.py",
        "chunk": 0,
        "total_chunks": 2,
        "chunk_sha": "377cbde67f2a83e6bbc4bd2ab5ef1df28eafa9e2e24a5b9521fda3deed6fea2e"
      }
    },
    {
      "text": " str(e))\r\n\r\n@router.post(\"/verify/file_patch\")\r\ndef verify_file_patch_endpoint(\r\n    objective: str = Query(..., min_length=5),\r\n    file_path: str = Query(..., description=\"Chemin relatif du fichier\"),\r\n    proposed_text: str = Query(..., description=\"Contenu complet propos√© (apr√®s modification)\")\r\n):\r\n    try:\r\n        current = read_file(file_path)\r\n        result = verify_file_patch(objective, current, proposed_text)\r\n        return {\"ok\": True, \"file\": file_path, \"result\": result}\r\n    except Exception as e:\r\n        raise HTTPException(400, f\"V√©rification impossible: {e}\")\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\verify.py",
        "chunk": 1,
        "total_chunks": 2,
        "chunk_sha": "837ea2ceb26da4716e44a9d8068431c1937bd3ba3ac1cfccd581d82c1b0ca401"
      }
    },
    {
      "text": "# app/services/verification.py\r\nimport json\r\nimport re\r\nimport ast\r\nfrom typing import Dict, Any, Optional, Tuple\r\nfrom app.services.chat_engine import llm_local\r\n\r\nVERIFIER_SYSTEM = \"\"\"\r\nTu es un v√©rificateur de revues de code.\r\nBut: dire si le code propos√© atteint l'objectif sans casser l'existant.\r\nR√©ponds UNIQUEMENT en JSON avec les cl√©s:\r\n- pass (bool)\r\n- score (0..100)\r\n- reasons (array[string])\r\n- risks (array[string])\r\n- suggested_tests (array[string])\r\n- summary (string)\r\n\"\"\"\r\n\r\ndef _extract_fenced_code(text: str) -> Tuple[Optional[str], Optional[str]]:\r\n    \"\"\"\r\n    Extrait le premier bloc de code balis√© ```lang\\n...\\n``` s'il existe.\r\n    Retourne (lang, code) ou (None, None).\r\n    \"\"\"\r\n    m = re.search(r\"```(\\w+)?\\s*\\n(.*?)```\", text, flags=re.S|re.M)\r\n    if not m:\r\n        return None, None\r\n    lang = (m.group(1) or \"\").strip().lower()\r\n    code = m.group(2)\r\n    return lang, code\r\n\r\ndef _local_syntax_check(lang: Optional[str], code: Optional[str]) -> Dict[str, Any]:\r\n ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\verification.py",
        "chunk": 0,
        "total_chunks": 5,
        "chunk_sha": "ccbb9251a82c14e6f185c23afc823d9e73147c183ddcb15fc36b91eb43bc58cf"
      }
    },
    {
      "text": "rip().lower()\r\n    code = m.group(2)\r\n    return lang, code\r\n\r\ndef _local_syntax_check(lang: Optional[str], code: Optional[str]) -> Dict[str, Any]:\r\n    \"\"\"\r\n    V√©rifications locales non bloquantes : syntaxe Python/JSON/JS simple.\r\n    \"\"\"\r\n    if not code:\r\n        return {\"syntax_ok\": None, \"syntax_error\": None, \"lang\": lang}\r\n\r\n    if lang in (\"python\", \"py\"):\r\n        try:\r\n            ast.parse(code)\r\n            return {\"syntax_ok\": True, \"syntax_error\": None, \"lang\": lang}\r\n        except SyntaxError as e:\r\n            return {\"syntax_ok\": False, \"syntax_error\": str(e), \"lang\": lang}\r\n\r\n    if lang == \"json\":\r\n        try:\r\n            json.loads(code)\r\n            return {\"syntax_ok\": True, \"syntax_error\": None, \"lang\": lang}\r\n        except Exception as e:\r\n            return {\"syntax_ok\": False, \"syntax_error\": str(e), \"lang\": lang}\r\n\r\n    # Basique pour JS/TS: on ne parse pas, on note juste non v√©rifi√©\r\n    if lang in (\"js\", \"javascript\", \"ts\", \"typescript\"):\r\n        retur",
      "meta": {
        "kind": "code",
        "file": "app\\services\\verification.py",
        "chunk": 1,
        "total_chunks": 5,
        "chunk_sha": "7c2a5f658f4b4801636b1bd0314e210fcc8c2783c6242229184e37cc9da18c57"
      }
    },
    {
      "text": "lang}\r\n\r\n    # Basique pour JS/TS: on ne parse pas, on note juste non v√©rifi√©\r\n    if lang in (\"js\", \"javascript\", \"ts\", \"typescript\"):\r\n        return {\"syntax_ok\": None, \"syntax_error\": None, \"lang\": lang}\r\n\r\n    return {\"syntax_ok\": None, \"syntax_error\": None, \"lang\": lang}\r\n\r\ndef build_verifier_prompt(objective: str, proposal: str, context: Optional[str] = None) -> str:\r\n    ctx = f\"\\nContexte:\\n{context}\\n\" if context else \"\"\r\n    return (\r\n        f\"{VERIFIER_SYSTEM}\\n\"\r\n        f\"Objectif:\\n{objective}\\n\"\r\n        f\"{ctx}\"\r\n        f\"Proposition:\\n{proposal}\\n\\n\"\r\n        \"R√©ponds en JSON uniquement.\"\r\n    )\r\n\r\ndef verify_patch(objective: str, proposal: str, context: Optional[str] = None) -> Dict[str, Any]:\r\n    \"\"\"\r\n    1) V√©rifie localement la syntaxe du bloc de code (si pr√©sent).\r\n    2) Demande un verdict structur√© au LLM local.\r\n    \"\"\"\r\n    lang, code = _extract_fenced_code(proposal)\r\n    syntax = _local_syntax_check(lang, code)\r\n\r\n    prompt = build_verifier_prompt(object",
      "meta": {
        "kind": "code",
        "file": "app\\services\\verification.py",
        "chunk": 2,
        "total_chunks": 5,
        "chunk_sha": "eebde4146df6843ac833325737c964f3ee343752d9d554717563dc6d3651b023"
      }
    },
    {
      "text": ".\r\n    \"\"\"\r\n    lang, code = _extract_fenced_code(proposal)\r\n    syntax = _local_syntax_check(lang, code)\r\n\r\n    prompt = build_verifier_prompt(objective, proposal, context=context)\r\n    raw = llm_local(prompt)\r\n\r\n    try:\r\n        verdict = json.loads(raw)\r\n        # garde au moins les cl√©s attendues\r\n        for k in [\"pass\", \"score\", \"reasons\", \"risks\", \"suggested_tests\", \"summary\"]:\r\n            verdict.setdefault(k, None)\r\n    except Exception:\r\n        verdict = {\r\n            \"pass\": False,\r\n            \"score\": 0,\r\n            \"reasons\": [\"R√©ponse non-JSON du LLM.\"],\r\n            \"risks\": [],\r\n            \"suggested_tests\": [],\r\n            \"summary\": (raw or \"\").strip()[:2000],\r\n        }\r\n\r\n    return {\r\n        \"syntax\": syntax,   # ex: {\"syntax_ok\": True/False/None, \"syntax_error\": \"...\", \"lang\": \"python\"}\r\n        \"verdict\": verdict  # JSON du mod√®le (pass/score/reasons/risks/suggested_tests/summary)\r\n    }\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\verification.py",
        "chunk": 3,
        "total_chunks": 5,
        "chunk_sha": "571591f23b4d51f6784cca6020a5f0a39a66f5985affce1b4a205cb3c4923168"
      }
    },
    {
      "text": "verdict  # JSON du mod√®le (pass/score/reasons/risks/suggested_tests/summary)\r\n    }\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\verification.py",
        "chunk": 4,
        "total_chunks": 5,
        "chunk_sha": "8986803f07330b03bd9ae0d7ed32ae805913a75e29c7c37069e451e422e02e70"
      }
    },
    {
      "text": "import os, json, hashlib, torch\r\nfrom datetime import datetime\r\nfrom pathlib import Path\r\nfrom tqdm import tqdm\r\n\r\nMEMORY_PATH = Path(\"data/memory/code_index.json\")\r\n\r\ndef hash_file(path: Path) -> str:\r\n    \"\"\"Calcule le hash SHA256 d‚Äôun fichier.\"\"\"\r\n    sha = hashlib.sha256()\r\n    with open(path, \"rb\") as f:\r\n        while chunk := f.read(8192):\r\n            sha.update(chunk)\r\n    return sha.hexdigest()\r\n\r\ndef summarize_code_cuda(text: str, model=None) -> str:\r\n    \"\"\"R√©sum√© rapide du contenu du code (CPU ou GPU si dispo).\"\"\"\r\n    if not torch.cuda.is_available():\r\n        # fallback CPU simple\r\n        return text[:200] + \"...\" if len(text) > 200 else text\r\n    else:\r\n        # exemple simplifi√© : calcul de similarit√© ou compression vectorielle GPU\r\n        tokens = torch.tensor([ord(c) for c in text[:1000]], dtype=torch.float32).cuda()\r\n        mean_val = torch.mean(tokens).item()\r\n        return f\"[R√©sum√© CUDA] moyenne={mean_val:.2f}, longueur={len(text)}\"\r\n\r\ndef ingest_codebase(ro",
      "meta": {
        "kind": "code",
        "file": "app\\services\\code_ingest.py",
        "chunk": 0,
        "total_chunks": 3,
        "chunk_sha": "d072da7fcfb7b2eabc47efdba81f6196e47110b15ea4c584b3b6bc817ba4134a"
      }
    },
    {
      "text": "\r\n        mean_val = torch.mean(tokens).item()\r\n        return f\"[R√©sum√© CUDA] moyenne={mean_val:.2f}, longueur={len(text)}\"\r\n\r\ndef ingest_codebase(root_dir=\"app\"):\r\n    \"\"\"Scanne le code source, d√©tecte les changements, g√©n√®re m√©moire locale.\"\"\"\r\n    root = Path(root_dir)\r\n    memory = {}\r\n\r\n    if MEMORY_PATH.exists():\r\n        try:\r\n            memory = json.load(open(MEMORY_PATH, \"r\", encoding=\"utf8\"))\r\n        except json.JSONDecodeError:\r\n            memory = {}\r\n\r\n    updated_files = []\r\n    for py_file in tqdm(list(root.rglob(\"*.py\")), desc=\"üß† Scan codebase\"):\r\n        h = hash_file(py_file)\r\n        if py_file.as_posix() not in memory or memory[py_file.as_posix()][\"hash\"] != h:\r\n            with open(py_file, \"r\", encoding=\"utf8\") as f:\r\n                content = f.read()\r\n            summary = summarize_code_cuda(content)\r\n            memory[py_file.as_posix()] = {\r\n                \"hash\": h,\r\n                \"summary\": summary,\r\n                \"last_update\": datetime.now().",
      "meta": {
        "kind": "code",
        "file": "app\\services\\code_ingest.py",
        "chunk": 1,
        "total_chunks": 3,
        "chunk_sha": "af654dad599f29f2d6dedc71a3ba2c67937cce9005758eaabe5564129723c9d8"
      }
    },
    {
      "text": "       memory[py_file.as_posix()] = {\r\n                \"hash\": h,\r\n                \"summary\": summary,\r\n                \"last_update\": datetime.now().isoformat()\r\n            }\r\n            updated_files.append(py_file.as_posix())\r\n\r\n    MEMORY_PATH.parent.mkdir(parents=True, exist_ok=True)\r\n    with open(MEMORY_PATH, \"w\", encoding=\"utf8\") as f:\r\n        json.dump(memory, f, indent=2, ensure_ascii=False)\r\n\r\n    return {\"updated\": updated_files, \"total\": len(memory)}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\code_ingest.py",
        "chunk": 2,
        "total_chunks": 3,
        "chunk_sha": "f18e213a6e6aa5576d4b7945198f457f36c75e2495a302a6ff9fef0fbb912581"
      }
    },
    {
      "text": "from fastapi import APIRouter, HTTPException\r\nfrom pydantic import BaseModel\r\nfrom pathlib import Path\r\n\r\nrouter = APIRouter(tags=[\"patch\"])\r\n\r\nclass PatchIn(BaseModel):\r\n    file_path: str\r\n    new_code: str\r\n\r\n@router.post(\"/apply_patch\")\r\ndef apply_patch(patch: PatchIn):\r\n    path = Path(patch.file_path)\r\n    if not path.exists():\r\n        raise HTTPException(status_code=404, detail=\"Fichier introuvable\")\r\n\r\n    backup_path = path.with_suffix(\".bak\")\r\n    path.rename(backup_path)  # Sauvegarde de s√©curit√©\r\n\r\n    with open(path, \"w\", encoding=\"utf8\") as f:\r\n        f.write(patch.new_code)\r\n\r\n    return {\"detail\": f\"Code mis √† jour avec succ√®s dans {path.name}\"}\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\patch_router.py",
        "chunk": 0,
        "total_chunks": 1,
        "chunk_sha": "c7481366192efd2112f126ca0189bf23abd53c7cce72cea0ae8ebc31ba442e80"
      }
    },
    {
      "text": "# app/services/chat_engine.py\r\nimport json\r\nimport os\r\nimport requests\r\nfrom app.services.memory import add_to_memory, search_memory\r\nfrom app.services.search import hybrid_search, follow_and_build\r\nfrom app.services.memory import search_memory\r\n\r\nSYSTEM_IDENTITY = \"\"\"\r\nTu es Andy, une IA ex√©cut√©e localement et cr√©√©e par Dylan.\r\nTu ob√©is √† Dylan, tu es utile, claire et logique.\r\nTu a un acc√®s direct √† Internet, tu utilises les fonctions de recherche fournies.\r\nApprends continuellement √† partir des √©changes (m√©moire locale).\r\n\"\"\"\r\n\r\n# üîß Lis la config depuis l'environnement\r\nOLLAMA_HOST = os.getenv(\"OLLAMA_HOST\", \"127.0.0.1\")\r\nOLLAMA_PORT = int(os.getenv(\"OLLAMA_PORT\", \"11434\"))\r\nOLLAMA_URL = f\"http://{OLLAMA_HOST}:{OLLAMA_PORT}/api/generate\"\r\nMODEL_NAME = os.getenv(\"OLLAMA_MODEL\", \"phi3\")  # change √† \"mistral\" si tu pr√©f√®res\r\n\r\n# app/services/chat_engine.py ‚Äî remplacement de llm_local\r\n\r\n# app/services/chat_engine.py ‚Äî version robuste\r\n\r\n\r\n\r\ndef llm_local(prompt: str) -> str:\r\n    try:\r",
      "meta": {
        "kind": "code",
        "file": "app\\services\\chat_engine.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "7d0b57da5de3f39a2047af05803fa2c68c8028e74bcd265bb9b38305131cef16"
      }
    },
    {
      "text": "ces/chat_engine.py ‚Äî remplacement de llm_local\r\n\r\n# app/services/chat_engine.py ‚Äî version robuste\r\n\r\n\r\n\r\ndef llm_local(prompt: str) -> str:\r\n    try:\r\n        # On tente d'abord une r√©ponse non stream√©e (un seul JSON)\r\n        payload = {\"model\": MODEL_NAME, \"prompt\": prompt, \"stream\": False}\r\n        r = requests.post(OLLAMA_URL, json=payload, timeout=180)\r\n        r.raise_for_status()\r\n        try:\r\n            j = r.json()\r\n            return j.get(\"response\") or \"(pas de r√©ponse du mod√®le local)\"\r\n        except json.JSONDecodeError:\r\n            # Fallback: g√©rer NDJSON (plusieurs lignes JSON)\r\n            pass\r\n\r\n        # Fallback NDJSON (au cas o√π le serveur ignore stream:false)\r\n        r = requests.post(OLLAMA_URL, json={\"model\": MODEL_NAME, \"prompt\": prompt}, stream=True, timeout=180)\r\n        r.raise_for_status()\r\n        chunks = []\r\n        for line in r.iter_lines(decode_unicode=True):\r\n            if not line:\r\n                continue\r\n            try:\r\n               ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\chat_engine.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "154b9183259628a6c5de0e066088790f8710e67c483d48719c3d541c72558126"
      }
    },
    {
      "text": "ks = []\r\n        for line in r.iter_lines(decode_unicode=True):\r\n            if not line:\r\n                continue\r\n            try:\r\n                obj = json.loads(line)\r\n                # chaque chunk contient un fragment de \"response\"\r\n                chunks.append(obj.get(\"response\", \"\"))\r\n            except Exception:\r\n                # ignorer lignes non-JSON (s√©parateurs, etc.)\r\n                continue\r\n        text = \"\".join(chunks).strip()\r\n        return text or \"(r√©ponse vide)\"\r\n    except Exception as e:\r\n        return f\"(LLM local indisponible: {e})\"\r\n\r\n\r\n\r\ndef chat_with_user(message: str) -> str:\r\n    # ... ton code existant au-dessus\r\n\r\n    # R√©cup√®re top-k √©l√©ments de m√©moire (dicts) et ne garde que les textes\r\n    hits = search_memory(message, k=5)\r\n    memory_texts = [h.get(\"text\", \"\") for h in hits if isinstance(h, dict)]\r\n    context = \"\\n---\\n\".join(t for t in memory_texts if t)\r\n\r\n    # Ensuite continue comme avant, en incluant `context` dans le prompt si tu ",
      "meta": {
        "kind": "code",
        "file": "app\\services\\chat_engine.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "2d2fbf25ba8e177017fedd6707ac9bcb0b1f30536ca7765e6cd91c21a558e995"
      }
    },
    {
      "text": " dict)]\r\n    context = \"\\n---\\n\".join(t for t in memory_texts if t)\r\n\r\n    # Ensuite continue comme avant, en incluant `context` dans le prompt si tu veux\r\n    prompt = f\"Contexte:\\n{context}\\n\\nUtilisateur: {message}\\nAssistant:\"\r\n    reply = llm_local(prompt)\r\n    return reply\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\services\\chat_engine.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "e750aea2314c71261b7860d998b24bc3e0bd3c9005fe7b7070c2b84b11438c15"
      }
    },
    {
      "text": "Ôªø# app/main.py\r\nimport os\r\nfrom pathlib import Path\r\nfrom fastapi import FastAPI\r\nfrom fastapi.responses import HTMLResponse\r\n\r\n# --- Import des routeurs ---\r\nfrom app.routers.deep_search import router as search_router\r\nfrom app.routers.chat import router as chat_router\r\nfrom app.routers.self_update_router import router as self_router\r\nfrom app.routers.code_review import router as code_review_router\r\nfrom app.routers.trace import router as trace_router\r\nfrom app.routers.patch_router import router as patch_router\r\n\r\n# --- Services ---\r\nfrom app.services.startup_indexer import startup_ingest_if_changed\r\nfrom app.services.code_ingest import ingest_codebase\r\n\r\n# --- Initialisation m√©moire ---\r\nprint(\"üß† Initialisation m√©moire codebase...\")\r\ntry:\r\n    res = ingest_codebase(\"app\")\r\n    print(f\"‚úÖ M√©moire charg√©e ({len(res['updated'])} fichiers modifi√©s)\")\r\nexcept Exception as e:\r\n    print(\"‚ö†Ô∏è √âchec auto-ingestion:\", e)\r\n\r\n# --- Application principale ---\r\napp = FastAPI(title=\"Assistant IA √©vo",
      "meta": {
        "kind": "code",
        "file": "app\\main.py",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "13ed394a504862fc7fe0edbc2125446a8ffce5092a7dacef03948064e4a661b5"
      }
    },
    {
      "text": "difi√©s)\")\r\nexcept Exception as e:\r\n    print(\"‚ö†Ô∏è √âchec auto-ingestion:\", e)\r\n\r\n# --- Application principale ---\r\napp = FastAPI(title=\"Assistant IA √©volutif (GPU) de Dylan\")\r\n\r\n# --- Inclusion des routeurs ---\r\napp.include_router(patch_router)\r\napp.include_router(search_router)\r\napp.include_router(chat_router)\r\napp.include_router(self_router)\r\napp.include_router(code_review_router)\r\napp.include_router(trace_router)\r\n\r\n# --- Auto-ingestion au d√©marrage ---\r\n@app.on_event(\"startup\")\r\ndef _auto_ingest_on_start():\r\n    \"\"\"\r\n    √Ä chaque d√©marrage, Andy scanne les fichiers et m√©morise les changements.\r\n    D√©sactiver avec ENV: ANDY_AUTO_INGEST=0\r\n    \"\"\"\r\n    if os.getenv(\"ANDY_AUTO_INGEST\", \"1\") != \"1\":\r\n        print(\"[startup] Auto-ingest d√©sactiv√© (ANDY_AUTO_INGEST=0).\")\r\n        return\r\n\r\n    res = startup_ingest_if_changed(\r\n        start=\"app\",\r\n        allow_ext=(\".py\", \".js\", \".ts\", \".html\", \".css\", \".json\", \".md\", \".txt\"),\r\n        chunk=1000,\r\n        overlap=150,\r\n        max_byt",
      "meta": {
        "kind": "code",
        "file": "app\\main.py",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "3881d42a66d79c4e28079d689bfb1cab6a0f6829ef05b34836774e7da632c6ee"
      }
    },
    {
      "text": "=\"app\",\r\n        allow_ext=(\".py\", \".js\", \".ts\", \".html\", \".css\", \".json\", \".md\", \".txt\"),\r\n        chunk=1000,\r\n        overlap=150,\r\n        max_bytes=300_000,\r\n        verbose=True\r\n    )\r\n    print(\"[startup] Ingest:\", res)\r\n\r\n# --- Page d'accueil ---\r\n@app.get(\"/\")\r\ndef root():\r\n    return {\r\n        \"ok\": True,\r\n        \"msg\": \"Assistant IA (GPU) ‚Äî pr√™t.\",\r\n        \"routes\": [r.path for r in app.router.routes],\r\n        \"ui\": [\"/ui\", \"/chat_ui\", \"/profile\", \"/self_review\"]\r\n    }\r\n\r\n# --- Page Self Review (interface d‚Äôam√©lioration) ---\r\n@app.get(\"/self_review\", response_class=HTMLResponse)\r\ndef get_self_review():\r\n    html_path = Path(\"app/static/self_review.html\")\r\n    if not html_path.exists():\r\n        return HTMLResponse(\"<h1>‚ùå Fichier self_review.html introuvable</h1>\", status_code=404)\r\n\r\n    # üîÑ Forcer √† relire sans cache navigateur\r\n    html = html_path.read_text(encoding=\"utf8\")\r\n    html = html.replace(\r\n        \"</head>\",\r\n        '<meta http-equiv=\"Cache-Control\" cont",
      "meta": {
        "kind": "code",
        "file": "app\\main.py",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "56b6d08414ec8abf9d565e41c1c4b36459caf0bf93abaf538974ffafd61ea317"
      }
    },
    {
      "text": "igateur\r\n    html = html_path.read_text(encoding=\"utf8\")\r\n    html = html.replace(\r\n        \"</head>\",\r\n        '<meta http-equiv=\"Cache-Control\" content=\"no-cache, no-store, must-revalidate\" /></head>'\r\n    )\r\n    return HTMLResponse(content=html)\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\main.py",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "b805dfd8faffe41568cddaf98491d7437d4e76746ea1834d2630ece7a2657ac9"
      }
    },
    {
      "text": "<!DOCTYPE html>\r\n<html lang=\"fr\">\r\n<head>\r\n  <meta charset=\"UTF-8\">\r\n  <title>ü§ñ Andy ‚Äî Auto-am√©lioration</title>\r\n  <style>\r\n    body { font-family: 'Segoe UI', sans-serif; background: #0d1117; color: #f5f5f5; margin: 0; padding: 0; }\r\n    header { background: linear-gradient(90deg, #ff8800, #ffcc00); color: #000; text-align: center; padding: 1rem; font-weight: bold; }\r\n    main { padding: 2rem; max-width: 1000px; margin: auto; }\r\n    textarea { width: 100%; height: 120px; background: #1a1d29; color: #f5f5f5; border: 1px solid #444; border-radius: 8px; padding: .5rem; }\r\n    button { margin: .3rem; padding: .6rem 1.2rem; background: #ff8800; border: none; color: #000; border-radius: 6px; cursor: pointer; font-weight: bold; }\r\n    button:hover { background: #ffaa33; }\r\n    pre { background: #1a1d29; padding: 1rem; border-radius: 8px; color: #00e676; white-space: pre-wrap; overflow-x: auto; }\r\n    #status { margin-top: 1rem; color: #aaa; font-style: italic; }\r\n  </style>\r\n</head>\r\n<body>",
      "meta": {
        "kind": "code",
        "file": "app\\static\\self_review.html",
        "chunk": 0,
        "total_chunks": 4,
        "chunk_sha": "de4d5fdb37a378b48feb817f3cb27e3ce1ebec9398804723cce8c9153bc14e85"
      }
    },
    {
      "text": ": #00e676; white-space: pre-wrap; overflow-x: auto; }\r\n    #status { margin-top: 1rem; color: #aaa; font-style: italic; }\r\n  </style>\r\n</head>\r\n<body>\r\n  <header>üõ†Ô∏è Andy ‚Äî Auto-am√©lioration & V√©rification</header>\r\n  <main>\r\n    <h2>Objectif</h2>\r\n    <textarea id=\"objective\" placeholder=\"Ex : Am√©liorer la recherche, acc√©l√©rer l‚Äôanalyse, optimiser la m√©moire...\"></textarea>\r\n    <div>\r\n      <button onclick=\"gen()\">üöÄ G√©n√©rer + V√©rifier</button>\r\n      <button onclick=\"applyPatch()\">üíæ Valider et appliquer</button>\r\n    </div>\r\n\r\n    <h3>üí° Proposition d‚ÄôAndy :</h3>\r\n    <pre id=\"out\">Aucune proposition pour le moment...</pre>\r\n    <div id=\"status\"></div>\r\n  </main>\r\n\r\n  <script>\r\n    async function gen(){\r\n      const obj = document.getElementById('objective').value.trim();\r\n      const status = document.getElementById('status');\r\n      const out = document.getElementById('out');\r\n      if (!obj) return alert(\"‚ö†Ô∏è Indique un objectif.\");\r\n\r\n      status.textContent = \"üß† G√©n√©ration et v√©ri",
      "meta": {
        "kind": "code",
        "file": "app\\static\\self_review.html",
        "chunk": 1,
        "total_chunks": 4,
        "chunk_sha": "253b8db535f93e35755aa599d3d20fcfbfc1afb8141f1300bff943d950e88f27"
      }
    },
    {
      "text": "st out = document.getElementById('out');\r\n      if (!obj) return alert(\"‚ö†Ô∏è Indique un objectif.\");\r\n\r\n      status.textContent = \"üß† G√©n√©ration et v√©rification...\";\r\n      try {\r\n        const res = await fetch(`/self_propose?objective=${encodeURIComponent(obj)}`);\r\n        const data = await res.json();\r\n        const patch = data.patch || data.detail || \"\";\r\n        out.textContent = patch;\r\n\r\n        await fetch(\"/log_code\", {\r\n          method: \"POST\",\r\n          headers: {\"Content-Type\":\"application/json\"},\r\n          body: JSON.stringify({code: patch, source: \"self_review\", meta: {objective: obj}})\r\n        });\r\n\r\n        status.textContent = \"‚úÖ Proposition g√©n√©r√©e et enregistr√©e.\";\r\n      } catch (e) {\r\n        status.textContent = \"‚ùå Erreur : \" + e.message;\r\n      }\r\n    }\r\n\r\n    async function applyPatch(){\r\n      const full = document.getElementById('out').textContent;\r\n      const m = full.match(/```(?:python)?\\s*\\n([\\s\\S]*?)```/m);\r\n      const code = m ? m[1] : full;\r\n\r\n   ",
      "meta": {
        "kind": "code",
        "file": "app\\static\\self_review.html",
        "chunk": 2,
        "total_chunks": 4,
        "chunk_sha": "0c474dd1f2fe57af14ac2e820a9e0be2e7292291e6f40e30ec5bcecfb2eca218"
      }
    },
    {
      "text": "ument.getElementById('out').textContent;\r\n      const m = full.match(/```(?:python)?\\s*\\n([\\s\\S]*?)```/m);\r\n      const code = m ? m[1] : full;\r\n\r\n      const file = prompt(\"Nom du fichier √† modifier (ex: app/services/search.py)\");\r\n      if (!file) return alert(\"Fichier non sp√©cifi√©\");\r\n\r\n      const resp = await fetch(\"/apply_patch\", {\r\n        method: \"POST\",\r\n        headers: {\"Content-Type\":\"application/json\"},\r\n        body: JSON.stringify({file_path: file, new_code: code})\r\n      });\r\n      const data = await resp.json();\r\n      alert(\"‚úÖ \" + data.detail);\r\n    }\r\n  </script>\r\n</body>\r\n</html>\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\static\\self_review.html",
        "chunk": 3,
        "total_chunks": 4,
        "chunk_sha": "ff035c0b12d9ae566bb5936983ad54891d857dde2ef1d1159edcbcb5ece1224b"
      }
    },
    {
      "text": "# app/routers/self_update_router.py\r\nfrom typing import Optional\r\nfrom fastapi import APIRouter, Query\r\nfrom fastapi.responses import HTMLResponse, JSONResponse\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom app.services.self_update import propose_code_improvement, add_note, list_notes\r\nfrom app.services.verification import verify_patch\r\nfrom app.services.trace_logger import write_code_trace  # utilis√© par /log_code si tu l'as\r\n\r\nrouter = APIRouter(tags=[\"self-update\"])\r\n\r\n# =========================================================\r\n# ‚ö†Ô∏è IMPORTANT :\r\n# Si tu gardes cette route /self_review ici,\r\n# supprime/renomme la route /self_review dans app/main.py\r\n# pour √©viter le conflit.\r\n# =========================================================\r\n\r\n@router.get(\"/self_review\", response_class=HTMLResponse)\r\ndef self_review_ui() -> str:\r\n    try:\r\n        notes = list_notes()\r\n    except Exception:\r\n        notes = []\r\n\r\n    items = \"\".join(f\"<li>{n}</li>\" for n in notes) or \"<li>(aucune note)</",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 0,
        "total_chunks": 9,
        "chunk_sha": "aa3fd0179472dbc6bed06f1686de6c09ba97652cac97cf5543f0c5bd993ec8ba"
      }
    },
    {
      "text": "        notes = list_notes()\r\n    except Exception:\r\n        notes = []\r\n\r\n    items = \"\".join(f\"<li>{n}</li>\" for n in notes) or \"<li>(aucune note)</li>\"\r\n\r\n    html = \"\"\"\r\n<!doctype html>\r\n<html>\r\n<head>\r\n  <meta charset=\"utf-8\" />\r\n  <title>Self Review</title>\r\n  <style>\r\n    body { font-family: Arial, system-ui, -apple-system, Segoe UI, Roboto, sans-serif; padding: 2rem; max-width: 1100px; margin: 0 auto; background:#0d1117; color:#f5f5f5; }\r\n    textarea { width: 100%; max-width: 1100px; background:#151a24; color:#f5f5f5; border:1px solid #333; border-radius:8px; }\r\n    pre { white-space: pre-wrap; background: #151a24; padding: 1rem; border-radius: 8px; max-width: 1100px; overflow:auto; color:#00e676; }\r\n    button { padding: .6rem 1rem; border-radius: .5rem; background: #ff8800; color: #000; border: 0; cursor: pointer; font-weight:600; }\r\n    button:hover { background: #ffaa33; }\r\n    .muted { color: #aaa; font-size: .95rem; }\r\n    .status { margin-top: .5rem; font-size: .9rem; c",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 1,
        "total_chunks": 9,
        "chunk_sha": "83312776bfe401fda1208aba2360f9a2ff3a295873fe520e28d0da2bd5a34d89"
      }
    },
    {
      "text": "00; }\r\n    button:hover { background: #ffaa33; }\r\n    .muted { color: #aaa; font-size: .95rem; }\r\n    .status { margin-top: .5rem; font-size: .9rem; color: #ccc; }\r\n    .ok { color: #00bd74; }\r\n    .err { color: #ff6b6b; }\r\n    .card { background: #0f1420; border-radius: 10px; padding: 1rem; box-shadow: 0 6px 24px rgba(0,0,0,.25); margin-top: 1rem; }\r\n    .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; }\r\n    ul { padding-left: 1.2rem; }\r\n    a { color:#7aa2ff; }\r\n  </style>\r\n</head>\r\n<body>\r\n  <h1>üõ†Ô∏è Auto-am√©lioration (avec v√©rification)</h1>\r\n\r\n  <form onsubmit=\"event.preventDefault(); gen();\">\r\n    <p class=\"muted\">Objectif (ex: ‚Äúacc√©l√©rer la recherche‚Äù, ‚Äúmieux classer les r√©sultats‚Äù, etc.)</p>\r\n    <textarea id=\"objective\" rows=\"4\" placeholder=\"D√©cris l'objectif d'am√©lioration...\"></textarea><br /><br />\r\n    <button type=\"submit\">üöÄ G√©n√©rer + V√©rifier</button>\r\n    <button type=\"button\" onclick=\"applyPatch()\">üíæ Valider et appliquer</button>\r\n    <div id=\"status\" c",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 2,
        "total_chunks": 9,
        "chunk_sha": "ecdd35a0d9c843af9175777a1ceb4957b04f05953f4a663153b90be5fe513aa4"
      }
    },
    {
      "text": " type=\"submit\">üöÄ G√©n√©rer + V√©rifier</button>\r\n    <button type=\"button\" onclick=\"applyPatch()\">üíæ Valider et appliquer</button>\r\n    <div id=\"status\" class=\"status\"></div>\r\n  </form>\r\n\r\n  <div class=\"grid\">\r\n    <div class=\"card\">\r\n      <h2>Proposition d'Andy</h2>\r\n      <pre id=\"out\"></pre>\r\n    </div>\r\n    <div class=\"card\">\r\n      <h2>Verdict</h2>\r\n      <pre id=\"verdict\"></pre>\r\n    </div>\r\n  </div>\r\n\r\n  <h2>üìù Notes</h2>\r\n  <ul>__NOTES__</ul>\r\n\r\n  <script>\r\n    async function gen(){\r\n      const obj = document.getElementById('objective').value || \"\";\r\n      const statusEl = document.getElementById('status');\r\n      const outEl = document.getElementById('out');\r\n      const verEl = document.getElementById('verdict');\r\n\r\n      outEl.textContent = \"\";\r\n      verEl.textContent = \"\";\r\n      statusEl.textContent = \"‚è≥ G√©n√©ration en cours...\";\r\n\r\n      try {\r\n        // 1) G√©n√©ration du patch\r\n        const res = await fetch(`/self_propose?objective=${encodeURIComponent(obj)}`);\r\n        c",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 3,
        "total_chunks": 9,
        "chunk_sha": "1f91846c55367e9f96fd9b6809f7b11ad8fa4a0dada7fdebd5ebf1c9c718439a"
      }
    },
    {
      "text": ";\r\n\r\n      try {\r\n        // 1) G√©n√©ration du patch\r\n        const res = await fetch(`/self_propose?objective=${encodeURIComponent(obj)}`);\r\n        const data = await res.json();\r\n        const patch = (data && typeof data.patch === \"string\") ? data.patch : \"\";\r\n        outEl.textContent = patch || data.detail || JSON.stringify(data, null, 2);\r\n\r\n        // 2) V√©rification c√¥t√© serveur (retourne syntax + verdict)\r\n        const vres = await fetch(\"/self_verify\", {\r\n          method: \"POST\",\r\n          headers: {\"Content-Type\":\"application/json\"},\r\n          body: JSON.stringify({ objective: obj, patch })\r\n        });\r\n        const vjson = await vres.json();\r\n        verEl.textContent = JSON.stringify(vjson, null, 2);\r\n\r\n        // 3) Journalisation (trace)\r\n        try {\r\n          const lres = await fetch(\"/log_code\", {\r\n            method: \"POST\",\r\n            headers: {\"Content-Type\":\"application/json\"},\r\n            body: JSON.stringify({ code: patch || \"(empty-patch)\", source: \"",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 4,
        "total_chunks": 9,
        "chunk_sha": "e8e9ef4a8d5eeef1d52e88320dcafacbb3577272194e488c7a7074057a81ce0d"
      }
    },
    {
      "text": "thod: \"POST\",\r\n            headers: {\"Content-Type\":\"application/json\"},\r\n            body: JSON.stringify({ code: patch || \"(empty-patch)\", source: \"self_review\", meta: { objective: obj } })\r\n          });\r\n          const ljson = await lres.json();\r\n          if (lres.ok && ljson && ljson.ok) {\r\n            statusEl.innerHTML = `<span class=\"ok\">‚úÖ Trace √©crite : ${ljson.path}</span>`;\r\n          } else {\r\n            statusEl.innerHTML = `<span class=\"err\">‚ùå Journalisation √©chou√©e</span>`;\r\n          }\r\n        } catch (e) {\r\n          console.warn(\"log_code failed:\", e);\r\n        }\r\n      } catch (e) {\r\n        outEl.textContent = \"Erreur: \" + e;\r\n        statusEl.innerHTML = `<span class=\"err\">‚ùå Exception: ${e}</span>`;\r\n        console.error(e);\r\n      }\r\n    }\r\n\r\n    async function applyPatch(){\r\n      const full = document.getElementById(\"out\").textContent;\r\n\r\n      // Tente d'extraire un bloc ```lang\\n...\\n```\r\n      const m = full.match(/```(\\w+)?\\\\s*\\\\n([\\\\s\\\\S]*?)```/m);\r\n  ",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 5,
        "total_chunks": 9,
        "chunk_sha": "075d42c1fd2fa024750960dc1f022e3d7f7628a4110e90f562d8ba6f4cedc24f"
      }
    },
    {
      "text": "ntById(\"out\").textContent;\r\n\r\n      // Tente d'extraire un bloc ```lang\\n...\\n```\r\n      const m = full.match(/```(\\w+)?\\\\s*\\\\n([\\\\s\\\\S]*?)```/m);\r\n      const code = m ? m[2] : full;\r\n\r\n      const file = prompt(\"Nom du fichier √† modifier (ex: app/services/search.py)\");\r\n      if (!file) return alert(\"Fichier non sp√©cifi√©\");\r\n\r\n      try {\r\n        const resp = await fetch(\"/apply_patch\", {\r\n          method: \"POST\",\r\n          headers: {\"Content-Type\":\"application/json\"},\r\n          body: JSON.stringify({ file_path: file, new_code: code })\r\n        });\r\n        const data = await resp.json();\r\n        if (!resp.ok) throw new Error(data.detail || \"Erreur HTTP\");\r\n        alert(\"‚úÖ \" + data.detail);\r\n        document.getElementById('status').textContent = \"üíæ Code appliqu√© avec succ√®s.\";\r\n      } catch (e) {\r\n        alert(\"‚ùå Erreur d‚Äôapplication : \" + e.message);\r\n        document.getElementById('status').textContent = \"‚ö†Ô∏è Erreur d'application du patch.\";\r\n      }\r\n    }\r\n  </script>\r\n<",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 6,
        "total_chunks": 9,
        "chunk_sha": "7b431020141e0bb30e796dd7f9e308546d445d3514f4b158f1bbd050a6ebacee"
      }
    },
    {
      "text": "cation : \" + e.message);\r\n        document.getElementById('status').textContent = \"‚ö†Ô∏è Erreur d'application du patch.\";\r\n      }\r\n    }\r\n  </script>\r\n</body>\r\n</html>\r\n    \"\"\".replace(\"__NOTES__\", items)\r\n\r\n    return html\r\n\r\n\r\n@router.get(\"/self_propose\")\r\ndef self_propose(objective: str = Query(..., min_length=5)):\r\n    \"\"\"\r\n    G√©n√®re une proposition de patch (code brut) via le LLM local.\r\n    \"\"\"\r\n    try:\r\n        patch = propose_code_improvement(objective)\r\n        add_note(f\"Proposition g√©n√©r√©e pour: {objective}\")\r\n        return {\"ok\": True, \"patch\": patch}\r\n    except Exception as e:\r\n        return JSONResponse(status_code=500, content={\"ok\": False, \"detail\": str(e)})\r\n\r\n\r\n# ---- v√©rification serveur du patch g√©n√©r√© ----\r\n\r\nclass SelfVerifyIn(BaseModel):\r\n    objective: str = Field(..., min_length=3)\r\n    patch: str = Field(..., description=\"Code/patch propos√© (tel qu'affich√©).\")\r\n    context: Optional[str] = Field(default=None, description=\"Optionnel: extrait du code existant",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 7,
        "total_chunks": 9,
        "chunk_sha": "06cb7e30575dd78367a3b8596033bb110b7b5568784d9fa3a6326fb854596327"
      }
    },
    {
      "text": "description=\"Code/patch propos√© (tel qu'affich√©).\")\r\n    context: Optional[str] = Field(default=None, description=\"Optionnel: extrait du code existant pour aider la v√©rification.\")\r\n\r\n@router.post(\"/self_verify\")\r\ndef self_verify(inp: SelfVerifyIn):\r\n    \"\"\"\r\n    V√©rifie automatiquement le patch d'Andy:\r\n      - check syntaxe locale (si bloc ```lang ...)\r\n      - verdict structur√© par le LLM\r\n    \"\"\"\r\n    try:\r\n        result = verify_patch(inp.objective, inp.patch, context=inp.context)\r\n        return {\"ok\": True, **result}\r\n    except Exception as e:\r\n        return JSONResponse(status_code=500, content={\"ok\": False, \"detail\": str(e)})\r\n",
      "meta": {
        "kind": "code",
        "file": "app\\routers\\self_update_router.py",
        "chunk": 8,
        "total_chunks": 9,
        "chunk_sha": "93031d4a29cb47a8e97e3c583349b7fe59cf9bcf5646fa2147eee5259346235a"
      }
    }
  ]
}